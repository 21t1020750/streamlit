import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
from PIL import Image
import joblib
import os
import mlflow
from mlflow.tracking import MlflowClient
import time
from datetime import datetime
from sklearn.preprocessing import StandardScaler
import random
from tensorflow.keras import layers

if "model_trained" not in st.session_state:
    st.session_state.model_trained = False

# H√†m chu·∫©n h√≥a d·ªØ li·ªáu
@st.cache_data
def standardize_data(X, fit=True, _scaler=None):
    if fit or _scaler is None:
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        return X_scaled, scaler
    else:
        return _scaler.transform(X), _scaler

# H√†m t·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML
def load_mnist_data():
    if "mnist_data" not in st.session_state:
        Xmt = np.load("buoi2/X.npy")
        ymt = np.load("buoi2/y.npy")
        X = Xmt.reshape(Xmt.shape[0], -1)  # Gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng d·ªØ li·ªáu
        y = ymt.reshape(-1)
        st.session_state["mnist_data"] = (X, y)
    return st.session_state["mnist_data"]

# H√†m chia d·ªØ li·ªáu
def split_data():
    st.title("üìå Chia d·ªØ li·ªáu Train/Test")
    
    # ƒê·ªçc d·ªØ li·ªáu
    X, y = load_mnist_data()
    total_samples = X.shape[0] 
    
    # Thanh k√©o ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train
    num_samples = st.slider("üìå Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ hu·∫•n luy·ªán:", 1000, total_samples, 10000)
    num_samples =num_samples -10
    # Thanh k√©o ch·ªçn t·ª∑ l·ªá Train/Test
    test_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20)
    train_size = 100 - test_size
    val_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Validation (trong Train)", 0, 50, 15)
    
    st.write(f"üìå **T·ª∑ l·ªá ph√¢n chia:** Test={test_size}%, Validation={val_size}%, Train={train_size - val_size}%")
    
    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u"):
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, stratify=y, random_state=42)
        X_train_full, X_test, y_train_full, y_test = train_test_split(X_selected, y_selected, test_size=test_size/100, stratify=y_selected, random_state=42)
        X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=val_size / (100 - test_size), stratify=y_train_full, random_state=42)
        
        # L∆∞u v√†o session_state
        st.session_state.update({
            "X_train": X_train, "X_val": X_val, "X_test": X_test,
            "y_train": y_train, "y_val": y_val, "y_test": y_test
        })
        
        summary_df = pd.DataFrame({"T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"], "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]})
        st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")
        st.table(summary_df)


# H√†m hu·∫•n luy·ªán m√¥ h√¨nh Neural Network
import streamlit as st
import mlflow
import mlflow.sklearn
from datetime import datetime
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.model_selection import StratifiedKFold
import tensorflow
from tensorflow import keras

def train():
   
    num=0
    if "X_train" not in st.session_state:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! H√£y chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return
    
    X_train, X_val, X_test = [st.session_state[k].reshape(-1, 28 * 28) / 255.0 for k in ["X_train", "X_val", "X_test"]]
    y_train, y_val, y_test = [st.session_state[k] for k in ["y_train", "y_val", "y_test"]]
    
    k_folds = st.slider("S·ªë fold cho Cross-Validation:", 3, 10, 5)
    num_layers = st.slider("S·ªë l·ªõp ·∫©n:", 1, 5, 2)
    num_neurons = st.slider("S·ªë neuron m·ªói l·ªõp:", 32, 512, 128, 32)
    activation = st.selectbox("H√†m k√≠ch ho·∫°t:", ["relu", "sigmoid", "tanh"])
    optimizer = st.selectbox("Optimizer:", ["adam", "sgd", "rmsprop"])
    epochs = st.slider("üï∞ S·ªë epochs:", min_value=1, max_value=50, value=20, step=1)
    learning_rate = st.slider("‚ö° T·ªëc ƒë·ªô h·ªçc (Learning Rate):", min_value=1e-5, max_value=1e-1, value=1e-3, step=1e-5, format="%.5f")

    loss_fn = "sparse_categorical_crossentropy"
    # Ch·ªâ nh·∫≠p t√™n Experiment (Kh√¥ng c√≥ ph·∫ßn nh·∫≠p t√™n Run)
    if "experiment_name" not in st.session_state:
        st.session_state["experiment_name"] = "My_Experiment"

    experiment_name = st.text_input("üîπ Nh·∫≠p t√™n Experiment:", st.session_state["experiment_name"], key="experiment_name_input")    

    if experiment_name:
        st.session_state["experiment_name"] = experiment_name

    mlflow.set_experiment(experiment_name)
    st.write(f"‚úÖ Experiment Name: {experiment_name}")
    
    if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
        if "run_name" not in st.session_state:
            st.session_state["run_name"] = f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}" 
        with st.spinner("ƒêang hu·∫•n luy·ªán..."):
            mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}")
            mlflow.log_params({
                "num_layers": num_layers,
                "num_neurons": num_neurons,
                "activation": activation,
                "optimizer": optimizer,
                "learning_rate": learning_rate,
                "k_folds": k_folds,
                "epochs": epochs
            })

            kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
            accuracies, losses = [], []

            # Thanh ti·∫øn tr√¨nh t·ªïng qu√°t cho to√†n b·ªô qu√° tr√¨nh hu·∫•n luy·ªán
            training_progress = st.progress(0)
            training_status = st.empty()

            for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):
                X_k_train, X_k_val = X_train[train_idx], X_train[val_idx]
                y_k_train, y_k_val = y_train[train_idx], y_train[val_idx]

                model = keras.Sequential([
                    layers.Input(shape=(X_k_train.shape[1],))
                ] + [
                    layers.Dense(num_neurons, activation=activation) for _ in range(num_layers)
                ] + [
                    layers.Dense(10, activation="softmax")
                ])

                # Ch·ªçn optimizer v·ªõi learning rate
                if optimizer == "adam":
                    opt = keras.optimizers.Adam(learning_rate=learning_rate)
                elif optimizer == "sgd":
                    opt = keras.optimizers.SGD(learning_rate=learning_rate)
                else:
                    opt = keras.optimizers.RMSprop(learning_rate=learning_rate)

                model.compile(optimizer=opt, loss=loss_fn, metrics=["accuracy"])

                start_time = time.time()
                history = model.fit(X_k_train, y_k_train, epochs=epochs, validation_data=(X_k_val, y_k_val), verbose=0)

                elapsed_time = time.time() - start_time
                accuracies.append(history.history["val_accuracy"][-1])
                losses.append(history.history["val_loss"][-1])

                # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh ch√≠nh (theo fold)
                
                
                progress_percent = int((num / k_folds)*100)
                
                num = num +1
                training_progress.progress(progress_percent)
                
                            

                
                training_status.text(f"‚è≥ ƒêang hu·∫•n luy·ªán... {progress_percent}%")

            avg_val_accuracy = np.mean(accuracies)
            avg_val_loss = np.mean(losses)

            mlflow.log_metrics({
                "avg_val_accuracy": avg_val_accuracy,
                "avg_val_loss": avg_val_loss,
                "elapsed_time": elapsed_time
            })

            test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
            mlflow.log_metrics({"test_accuracy": test_accuracy, "test_loss": test_loss})

            mlflow.end_run()
            st.session_state["trained_model"] = model

            # Ho√†n th√†nh ti·∫øn tr√¨nh
            training_progress.progress(1.0)
            training_status.text("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")

            st.success(f"‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
            st.write(f"üìä **ƒê·ªô ch√≠nh x√°c trung b√¨nh tr√™n t·∫≠p validation:** {avg_val_accuracy:.4f}")
            st.write(f"üìä **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p test:** {test_accuracy:.4f}")
       
            st.success(f"‚úÖ ƒê√£ log d·ªØ li·ªáu cho Experiments Neural_Network v·ªõi Name: **Train_{st.session_state['run_name']}**!")
            st.markdown(f"üîó [Truy c·∫≠p MLflow UI]({st.session_state['mlflow_url']})")


        
# X·ª≠ l√Ω ·∫£nh t·ª´ canvas
def preprocess_canvas_image(canvas_result):
    """Chuy·ªÉn ƒë·ªïi ·∫£nh t·ª´ canvas sang ƒë·ªãnh d·∫°ng ph√π h·ª£p ƒë·ªÉ d·ª± ƒëo√°n."""
    if canvas_result.image_data is None:
        return None
    img = canvas_result.image_data[:, :, :3]  # Ch·ªâ l·∫•y 3 k√™nh RGB
    img = Image.fromarray(img).convert("L").resize((28, 28))  # Chuy·ªÉn sang grayscale, resize v·ªÅ 28x28
    img = np.array(img) / 255.0  # Chu·∫©n h√≥a v·ªÅ [0,1]
    img = img.reshape(1, -1)  # ƒê∆∞a v·ªÅ d·∫°ng vector gi·ªëng nh∆∞ trong `thi_nghiem()`
    return img

# H√†m d·ª± ƒëo√°n
def du_doan():
    st.header("‚úçÔ∏è V·∫Ω s·ªë ƒë·ªÉ d·ª± ƒëo√°n")

    # üì• Load m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
    if "trained_model" in st.session_state:
        model = st.session_state["trained_model"]
        st.success("‚úÖ ƒê√£ s·ª≠ d·ª•ng m√¥ h√¨nh v·ª´a hu·∫•n luy·ªán!")
    else:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ m√¥ h√¨nh! H√£y hu·∫•n luy·ªán tr∆∞·ªõc.")


    # üÜï C·∫≠p nh·∫≠t key cho canvas khi nh·∫•n "T·∫£i l·∫°i"
    if "key_value" not in st.session_state:
        st.session_state.key_value = str(random.randint(0, 1000000))  

    if st.button("üîÑ T·∫£i l·∫°i n·∫øu kh√¥ng th·∫•y canvas"):
        st.session_state.key_value = str(random.randint(0, 1000000))  

    # ‚úçÔ∏è V·∫Ω s·ªë
    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key=st.session_state.key_value,
        update_streamlit=True
    )

    if st.button("D·ª± ƒëo√°n s·ªë"):
        img = preprocess_canvas_image(canvas_result)

        if img is not None:
            st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="·∫¢nh sau x·ª≠ l√Ω", width=100)

            # D·ª± ƒëo√°n s·ªë
            prediction = model.predict(img)
            predicted_number = np.argmax(prediction, axis=1)[0]
            max_confidence = np.max(prediction)

            st.subheader(f"üî¢ D·ª± ƒëo√°n: {predicted_number}")
            st.write(f"üìä M·ª©c ƒë·ªô tin c·∫≠y: {max_confidence:.2%}")

            # Hi·ªÉn th·ªã b·∫£ng confidence score
            prob_df = pd.DataFrame(prediction.reshape(1, -1), columns=[str(i) for i in range(10)]).T
            prob_df.columns = ["M·ª©c ƒë·ªô tin c·∫≠y"]
            st.bar_chart(prob_df)

        else:
            st.error("‚ö†Ô∏è H√£y v·∫Ω m·ªôt s·ªë tr∆∞·ªõc khi b·∫•m D·ª± ƒëo√°n!")

from datetime import datetime

def show_experiment_selector():
    st.title("üìä MLflow Experiments - DAGsHub")

    # L·∫•y danh s√°ch t·∫•t c·∫£ experiments
    experiments = mlflow.search_experiments()
    experiment_names = [exp.name for exp in experiments]    
    # T√¨m experiment theo t√™n
    
    selected_experiment_name = st.selectbox("üîç Ch·ªçn m·ªôt Experiment:", experiment_names)

    if not selected_experiment_name:
        st.error(f"‚ùå Experiment '{selected_experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return
    selected_experiment = next((exp for exp in experiments if exp.name == selected_experiment_name), None)

    if not selected_experiment:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y experiment trong danh s√°ch.")
        return
    st.subheader(f"üìå Experiment: {selected_experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # L·∫•y danh s√°ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    st.write("### üèÉ‚Äç‚ôÇÔ∏è C√°c Runs g·∫ßn ƒë√¢y:")

    # L·∫•y danh s√°ch run_name t·ª´ params
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_params = mlflow.get_run(run_id).data.params
        run_name = run_params.get("run_name", f"Run {run_id[:8]}")  # N·∫øu kh√¥ng c√≥ t√™n, l·∫•y 8 k√Ω t·ª± ƒë·∫ßu c·ªßa ID
        run_info.append((run_name, run_id))
    # ƒê·∫£m b·∫£o danh s√°ch run_info ƒë∆∞·ª£c s·∫Øp x·∫øp theo th·ªùi gian ch·∫°y g·∫ßn nh·∫•t
    run_info.sort(key=lambda x: mlflow.get_run(x[1]).info.start_time, reverse=True)
    
    # T·∫°o dictionary ƒë·ªÉ map run_name -> run_id
    # L·∫•y run g·∫ßn nh·∫•t
    if run_info:
        latest_run_name, latest_run_id = run_info[0]  # Ch·ªçn run m·ªõi nh·∫•t
        selected_run_name = latest_run_name
        selected_run_id = latest_run_id
    else:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt c·ªßa run ƒë∆∞·ª£c ch·ªçn
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")
        start_time_ms = selected_run.info.start_time  # Th·ªùi gian l∆∞u d∆∞·ªõi d·∫°ng milliseconds

        # Chuy·ªÉn sang ƒë·ªãnh d·∫°ng ng√†y gi·ªù d·ªÖ ƒë·ªçc
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "Kh√¥ng c√≥ th√¥ng tin"

        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        # Hi·ªÉn th·ªã th√¥ng s·ªë ƒë√£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

        # Ki·ªÉm tra v√† hi·ªÉn th·ªã dataset artifact
        dataset_uri = f"{selected_experiment.artifact_location}/{selected_run_id}/artifacts/dataset.csv" 
        try:
            mlflow.artifacts.download_artifacts(dataset_uri)
            st.write("### üìÇ Dataset:")
            st.write(f"üì• [T·∫£i dataset]({dataset_uri})")
        except Exception as e:
            st.warning("‚ö† Kh√¥ng t√¨m th·∫•y dataset.csv trong artifacts.")
# H√†m l√Ω thuy·∫øt Neural Network
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt


# H√†m l√Ω thuy·∫øt Neural Network d·ª±a tr√™n t√†i li·ªáu
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt


# H√†m l√Ω thuy·∫øt Neural Network
def explain_neural_network():
    # Ti√™u ƒë·ªÅ ch√≠nh
    st.title("üß† Hi·ªÉu Bi·∫øt C∆° B·∫£n V·ªÅ M·∫°ng N∆°-ron Nh√¢n T·∫°o")
    gif_path = "buoi5/g1.gif"  
    st.image(gif_path, caption="H√¨nh ·∫£nh minh h·ªça d·ªØ li·ªáu MNIST", use_container_width="auto")
    # Gi·ªõi thi·ªáu
    st.markdown("""
    **M·∫°ng n∆°-ron nh√¢n t·∫°o (Artificial Neural Network - ANN)** l√† m·ªôt m√¥ h√¨nh t√≠nh to√°n ƒë∆∞·ª£c l·∫•y c·∫£m h·ª©ng t·ª´ c√°ch ho·∫°t ƒë·ªông c·ªßa n√£o b·ªô con ng∆∞·ªùi. N√≥ bao g·ªìm nhi·ªÅu ƒë∆°n v·ªã x·ª≠ l√Ω g·ªçi l√† n∆°-ron, ƒë∆∞·ª£c li√™n k·∫øt v·ªõi nhau qua c√°c l·ªõp (layers), cho ph√©p m√¥ h√¨nh h·ªçc h·ªèi v√† nh·∫≠n di·ªán c√°c ƒë·∫∑c ƒëi·ªÉm ho·∫∑c quy lu·∫≠t t·ª´ d·ªØ li·ªáu.
    """)

    # C·∫•u tr√∫c m·∫°ng n∆°-ron
    st.subheader("üîç C·∫•u tr√∫c ch√≠nh c·ªßa m·∫°ng n∆°-ron")
    st.markdown("""
    M·∫°ng n∆°-ron th∆∞·ªùng ƒë∆∞·ª£c chia th√†nh ba ph·∫ßn c∆° b·∫£n:
    1. **L·ªõp ƒë·∫ßu v√†o (Input Layer):** N∆°i d·ªØ li·ªáu ƒë∆∞·ª£c ƒë∆∞a v√†o h·ªá th·ªëng.
    2. **L·ªõp ·∫©n (Hidden Layers):** C√°c l·ªõp trung gian ch·ªãu tr√°ch nhi·ªám x·ª≠ l√Ω th√¥ng tin b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c tr·ªçng s·ªë (weights) v√† h√†m k√≠ch ho·∫°t (activation function).
    3. **L·ªõp ƒë·∫ßu ra (Output Layer):** ƒê∆∞a ra k·∫øt qu·∫£ cu·ªëi c√πng, ch·∫≥ng h·∫°n nh∆∞ d·ª± ƒëo√°n ho·∫∑c ph√¢n lo·∫°i.
    
    *V√≠ d·ª•:* N·∫øu b·∫°n t∆∞·ªüng t∆∞·ª£ng m·∫°ng n∆°-ron nh∆∞ m·ªôt nh√† m√°y, l·ªõp ƒë·∫ßu v√†o l√† nguy√™n li·ªáu th√¥, c√°c l·ªõp ·∫©n l√† d√¢y chuy·ªÅn s·∫£n xu·∫•t, v√† l·ªõp ƒë·∫ßu ra l√† s·∫£n ph·∫©m ho√†n thi·ªán.
    """)
    st.image("buoi5/oXvOtJt.png", caption="C·∫•u tr√∫c m·∫°ng n∆°-ron(mmlab.uit.edu.vn)", use_container_width="auto")
    # Ghi ch√∫: N·∫øu c√≥ h√¨nh ·∫£nh, b·∫°n c√≥ th·ªÉ th√™m b·∫±ng st.image("ƒë∆∞·ªùng_d·∫´n_h√¨nh_·∫£nh")

    # C√°ch ho·∫°t ƒë·ªông c·ªßa n∆°-ron
    st.subheader("‚öôÔ∏è C√°ch ho·∫°t ƒë·ªông c·ªßa m·ªôt n∆°-ron")
    st.markdown("""
    M·ªói n∆°-ron trong m·∫°ng nh·∫≠n t√≠n hi·ªáu t·ª´ c√°c n∆°-ron ·ªü l·ªõp tr∆∞·ªõc, nh√¢n ch√∫ng v·ªõi c√°c tr·ªçng s·ªë, c·ªông th√™m m·ªôt gi√° tr·ªã g·ªçi l√† **bias**, r·ªìi √°p d·ª•ng m·ªôt h√†m k√≠ch ho·∫°t ƒë·ªÉ quy·∫øt ƒë·ªãnh t√≠n hi·ªáu n√†o s·∫Ω ƒë∆∞·ª£c truy·ªÅn ti·∫øp.
    """)
    st.markdown("### C√¥ng th·ª©c c∆° b·∫£n c·ªßa m·ªôt n∆°-ron:")
    st.latex(r"z = w_1x_1 + w_2x_2 + \dots + w_nx_n + b")
    st.markdown("""
    Trong ƒë√≥:
    - $$ x_1, x_2, \dots, x_n $$: C√°c gi√° tr·ªã ƒë·∫ßu v√†o.
    - $$ w_1, w_2, \dots, w_n $$: Tr·ªçng s·ªë t∆∞∆°ng ·ª©ng.
    - $$ b $$: Gi√° tr·ªã bias.
    - $$ z $$: T·ªïng c√≥ tr·ªçng s·ªë.
    
    Sau khi t√≠nh $$ z $$, gi√° tr·ªã n√†y s·∫Ω ƒë∆∞·ª£c ƒë∆∞a qua m·ªôt **h√†m k√≠ch ho·∫°t** ƒë·ªÉ t·∫°o ra ƒë·∫ßu ra cu·ªëi c√πng c·ªßa n∆°-ron.
    """)

    # H√†m k√≠ch ho·∫°t
    st.subheader("üéØ C√°c h√†m k√≠ch ho·∫°t ph·ªï bi·∫øn")
    st.markdown("""
    H√†m k√≠ch ho·∫°t ƒë√≥ng vai tr√≤ quan tr·ªçng trong vi·ªác gi√∫p m·∫°ng n∆°-ron x·ª≠ l√Ω c√°c v·∫•n ƒë·ªÅ ph·ª©c t·∫°p, ƒë·∫∑c bi·ªát l√† nh·ªØng m·ªëi quan h·ªá phi tuy·∫øn t√≠nh trong d·ªØ li·ªáu. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë h√†m ph·ªï bi·∫øn:
    """)
    st.image("buoi5/tmkfP14.png", caption="h√†m k√≠ch ho·∫°t c·ªßa Sigmoid v√† Tanh ", use_container_width="auto")
    st.markdown("""
    1. **Sigmoid:** Bi·∫øn ƒë·ªïi ƒë·∫ßu v√†o th√†nh gi√° tr·ªã t·ª´ 0 ƒë·∫øn 1, th∆∞·ªùng d√πng cho b√†i to√°n ph√¢n lo·∫°i hai l·ªõp.
    """)
    st.latex(r"f(z) = \frac{1}{1 + e^{-z}}")
    
    st.markdown("""
    2. **Tanh:** ƒê∆∞a ƒë·∫ßu ra v√†o kho·∫£ng t·ª´ -1 ƒë·∫øn 1, ph√π h·ª£p v·ªõi d·ªØ li·ªáu c√≥ gi√° tr·ªã √¢m v√† d∆∞∆°ng.
    """)
    st.latex(r"f(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}")
    

    st.markdown("""
    3. **ReLU:** ƒê∆°n gi·∫£n nh∆∞ng hi·ªáu qu·∫£, tr·∫£ v·ªÅ 0 n·∫øu ƒë·∫ßu v√†o √¢m v√† gi·ªØ nguy√™n gi√° tr·ªã n·∫øu d∆∞∆°ng.
    """)
    st.latex(r"f(z) = \max(0, z)")
    st.image("buoi5/UmoHHfH.png", caption="h√†m k√≠ch ho·∫°t c·ªßa ReLU", use_container_width="auto")
    # Qu√° tr√¨nh h·ªçc
    st.subheader("üîÑ Qu√° tr√¨nh h·ªçc c·ªßa m·∫°ng n∆°-ron")
    st.markdown("""
    M·∫°ng n∆°-ron h·ªçc th√¥ng qua vi·ªác ƒëi·ªÅu ch·ªânh tr·ªçng s·ªë d·ª±a tr√™n hai b∆∞·ªõc ch√≠nh: **lan truy·ªÅn thu·∫≠n** v√† **lan truy·ªÅn ng∆∞·ª£c**.
    """)

    # Lan truy·ªÅn thu·∫≠n
    st.markdown("#### 1. Lan truy·ªÅn thu·∫≠n (Forward Propagation)")
    st.markdown("""
    D·ªØ li·ªáu ƒë∆∞·ª£c ƒë∆∞a t·ª´ l·ªõp ƒë·∫ßu v√†o qua c√°c l·ªõp ·∫©n, r·ªìi ƒë·∫øn l·ªõp ƒë·∫ßu ra. M·ªói l·ªõp th·ª±c hi·ªán ph√©p t√≠nh:
    """)
    st.latex(r"f^{(l)} = \sigma(W^{(l)} f^{(l-1)} + b^{(l)})")
    st.markdown("""
    - $$ f^{(l)} $$: ƒê·∫ßu ra c·ªßa l·ªõp th·ª© $$ l $$.
    - $$ W^{(l)} $$: Ma tr·∫≠n tr·ªçng s·ªë c·ªßa l·ªõp $$ l $$.
    - $$ b^{(l)} $$: Bias c·ªßa l·ªõp $$ l $$.
    - $$ \sigma $$: H√†m k√≠ch ho·∫°t.
    """)

    # T√≠nh to√°n sai s·ªë
    st.markdown("#### 2. T√≠nh to√°n sai s·ªë (Loss Function)")
    st.markdown("""
    Sai s·ªë gi·ªØa k·∫øt qu·∫£ d·ª± ƒëo√°n v√† gi√° tr·ªã th·ª±c t·∫ø ƒë∆∞·ª£c ƒëo b·∫±ng h√†m m·∫•t m√°t, v√≠ d·ª•:
    - **Mean Squared Error (MSE):** D√πng cho b√†i to√°n h·ªìi quy:
    """)
    st.latex(r"L = \frac{1}{N} \sum (y_{th·ª±c} - y_{d·ª± ƒëo√°n})^2")
    st.markdown("""
    - **Cross-Entropy Loss:** D√πng cho b√†i to√°n ph√¢n lo·∫°i:
    """)
    st.latex(r"L = - \sum y_{th·ª±c} \log(y_{d·ª± ƒëo√°n})")

    # Lan truy·ªÅn ng∆∞·ª£c
    st.markdown("#### 3. Lan truy·ªÅn ng∆∞·ª£c (Backpropagation)")
    st.markdown("""
    M·∫°ng s·ª≠ d·ª•ng ƒë·∫°o h√†m c·ªßa h√†m m·∫•t m√°t ƒë·ªÉ ƒëi·ªÅu ch·ªânh tr·ªçng s·ªë:
    """)
    st.latex(r"\frac{\partial L}{\partial W^{(l)}} = \frac{\partial L}{\partial a^{(l)}} \cdot \frac{\partial a^{(l)}}{\partial z^{(l)}} \cdot \frac{\partial z^{(l)}}{\partial W^{(l)}}")
    st.markdown("""
    Qu√° tr√¨nh n√†y gi√∫p m·∫°ng ‚Äúh·ªçc‚Äù b·∫±ng c√°ch gi·∫£m d·∫ßn sai s·ªë.
    """)

    # T·ªëi ∆∞u h√≥a
    st.markdown("#### 4. T·ªëi ∆∞u h√≥a tr·ªçng s·ªë")
    st.markdown("""
    ƒê·ªÉ c·∫≠p nh·∫≠t tr·ªçng s·ªë, c√°c thu·∫≠t to√°n t·ªëi ∆∞u ƒë∆∞·ª£c s·ª≠ d·ª•ng:
    - **Gradient Descent:** Di chuy·ªÉn tr·ªçng s·ªë theo h∆∞·ªõng gi·∫£m gradient:
    """)
    st.latex(r"W^{(l)} = W^{(l)} - \alpha \frac{\partial L}{\partial W^{(l)}}")
    st.markdown("""
    - **Adam:** K·∫øt h·ª£p ƒë·ªông l∆∞·ª£ng v√† ƒëi·ªÅu ch·ªânh t·ªëc ƒë·ªô h·ªçc:
    """)
    st.latex(r"W^{(l)} = W^{(l)} - \alpha \frac{\hat{m_t}}{\sqrt{\hat{v_t}} + \epsilon}")

    # K·∫øt lu·∫≠n
    st.subheader("üåü T·ªïng k·∫øt")
    st.markdown("""
    M·∫°ng n∆°-ron nh√¢n t·∫°o l√† m·ªôt c√¥ng c·ª• m·∫°nh m·∫Ω trong h·ªçc m√°y, c√≥ kh·∫£ nƒÉng h·ªçc h·ªèi t·ª´ d·ªØ li·ªáu ph·ª©c t·∫°p. Vi·ªác n·∫Øm r√µ c√°ch n√≥ ho·∫°t ƒë·ªông ‚Äì t·ª´ c·∫•u tr√∫c, h√†m k√≠ch ho·∫°t, ƒë·∫øn qu√° tr√¨nh hu·∫•n luy·ªán ‚Äì l√† ch√¨a kh√≥a ƒë·ªÉ √°p d·ª•ng v√† c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh trong th·ª±c t·∫ø.
    """)
# H√†m hi·ªÉn th·ªã th√¥ng tin v·ªÅ MNIST
def data():
    st.title("Kh√°m Ph√° B·ªô D·ªØ Li·ªáu MNIST")
   

    st.markdown("""
        <div style="background-color: #F0F8FF; padding: 20px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            <h2 style="color: #32CD32; font-size: 32px;">üìä T·ªïng Quan V·ªÅ MNIST</h2>
            <p style="font-size: 20px; color: #333; text-align: justify;">
                MNIST (Modified National Institute of Standards and Technology) l√† b·ªô d·ªØ li·ªáu <b>huy·ªÅn tho·∫°i</b> 
                trong nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay, v·ªõi <b>70.000 ·∫£nh</b> (60.000 train, 10.000 test), m·ªói ·∫£nh 
                c√≥ k√≠ch th∆∞·ªõc <b>28x28 pixel</b> grayscale.
            </p>
        </div>
    """, unsafe_allow_html=True)

    X, y = load_mnist_data()
    fig, ax = plt.subplots(1, 5, figsize=(15, 3))
    for i in range(5):
        ax[i].imshow(X[i].reshape(28, 28), cmap='gray')
        ax[i].axis('off')
        ax[i].set_title(f"Nh√£n: {int(y[i])}")
    # S·ª≠ d·ª•ng st.pyplot() thay v√¨ st.image()
    st.pyplot(fig)

    st.markdown("""
        <h2 style="color: #FF4500; font-size: 32px;">üåç ·ª®ng D·ª•ng Th·ª±c T·∫ø</h2>
        <div style="display: flex; gap: 20px;">
            <div style="background-color: #ECF0F1; padding: 15px; border-radius: 10px; flex: 1;">
                <p style="font-size: 20px; color: #2E86C1;">Nh·∫≠n di·ªán s·ªë tr√™n h√≥a ƒë∆°n.</p>
            </div>
            <div style="background-color: #ECF0F1; padding: 15px; border-radius: 10px; flex: 1;">
                <p style="font-size: 20px; color: #2E86C1;">X·ª≠ l√Ω m√£ b∆∞u ki·ªán.</p>
            </div>
        </div>
    """, unsafe_allow_html=True)

    st.markdown("<h2 style='color: #8A2BE2; font-size: 32px;'>üèÜ Hi·ªáu Su·∫•t M√¥ H√¨nh</h2>", unsafe_allow_html=True)
    data = {"M√¥ h√¨nh": ["Neural Network", "SVM", "CNN"], "ƒê·ªô ch√≠nh x√°c": ["0.98", "0.97", "0.99"]}
    df = pd.DataFrame(data)
    st.table(df.style.set_properties(**{'background-color': '#F5F5F5', 'border': '1px solid #DDD', 'text-align': 'center', 'font-size': '18px'}).set_table_styles([{'selector': 'th', 'props': [('background-color', '#3498DB'), ('color', 'white')]}]))
    
def Classification():
    if "mlflow_initialized" not in st.session_state:
        DAGSHUB_MLFLOW_URI = "https://dagshub.com/PTToan250303/Linear_replication.mlflow"
        mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
        st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
        os.environ["MLFLOW_TRACKING_USERNAME"] = "PTToan250303"
        os.environ["MLFLOW_TRACKING_PASSWORD"] = "5ca8caf353d564c358852da97c7487e64fc30a73"
        mlflow.set_experiment("Neural_Network_Classification")
    st.markdown("""
        <style>
        .title { font-size: 48px; font-weight: bold; text-align: center; color: #4682B4; margin-top: 50px; }
        .subtitle { font-size: 24px; text-align: center; color: #4A4A4A; }
        hr { border: 1px solid #ddd; }
        </style>
        <div class="title">MNIST Neural Network App</div>
        <hr>
    """, unsafe_allow_html=True)

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìò L√Ω thuy·∫øt Neural Network", "üìò Data", "‚öôÔ∏è Hu·∫•n luy·ªán", "üî¢ D·ª± ƒëo√°n", "üî• Mlflow"])

    with tab1:
        explain_neural_network()
    with tab2:
        data()
    with tab3:
        split_data()
        train()
    with tab4:
        du_doan()
    with tab5:
        show_experiment_selector()

if __name__ == "__main__":
   Classification()