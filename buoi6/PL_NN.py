import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
from PIL import Image
import joblib
import os
import mlflow
from mlflow.tracking import MlflowClient
import time
from datetime import datetime
from sklearn.preprocessing import StandardScaler
import random
from tensorflow.keras import layers

if "model_trained" not in st.session_state:
    st.session_state.model_trained = False

# HÃ m chuáº©n hÃ³a dá»¯ liá»‡u
@st.cache_data
def standardize_data(X, fit=True, _scaler=None):
    if fit or _scaler is None:
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        return X_scaled, scaler
    else:
        return _scaler.transform(X), _scaler

# HÃ m táº£i dá»¯ liá»‡u MNIST tá»« OpenML
def load_mnist_data():
    if "mnist_data" not in st.session_state:
        Xmt = np.load("buoi2/X.npy")
        ymt = np.load("buoi2/y.npy")
        X = Xmt.reshape(Xmt.shape[0], -1)  # Giá»¯ nguyÃªn Ä‘á»‹nh dáº¡ng dá»¯ liá»‡u
        y = ymt.reshape(-1)
        st.session_state["mnist_data"] = (X, y)
    return st.session_state["mnist_data"]

# HÃ m chia dá»¯ liá»‡u
def split_data():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")
    
    # Äá»c dá»¯ liá»‡u
    X, y = load_mnist_data()
    total_samples = X.shape[0] 
    
    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
    num_samples = st.slider("ğŸ“Œ Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ huáº¥n luyá»‡n:", 1000, total_samples, 10000)
    num_samples =num_samples -10
    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test
    test_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Test", 10, 50, 20)
    train_size = 100 - test_size
    val_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Validation (trong Train)", 0, 50, 15)
    
    st.write(f"ğŸ“Œ **Tá»· lá»‡ phÃ¢n chia:** Test={test_size}%, Validation={val_size}%, Train={train_size - val_size}%")
    
    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, stratify=y, random_state=42)
        X_train_full, X_test, y_train_full, y_test = train_test_split(X_selected, y_selected, test_size=test_size/100, stratify=y_selected, random_state=42)
        X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=val_size / (100 - test_size), stratify=y_train_full, random_state=42)
        
        # LÆ°u vÃ o session_state
        st.session_state.update({
            "X_train": X_train, "X_val": X_val, "X_test": X_test,
            "y_train": y_train, "y_val": y_val, "y_test": y_test
        })
        
        summary_df = pd.DataFrame({"Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"], "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]})
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")
        st.table(summary_df)


# HÃ m huáº¥n luyá»‡n mÃ´ hÃ¬nh Neural Network
import streamlit as st
import mlflow
import mlflow.sklearn
from datetime import datetime
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.model_selection import StratifiedKFold
import tensorflow
from tensorflow import keras

def train():
    # Khá»Ÿi táº¡o cÃ¡c biáº¿n trong session_state náº¿u chÆ°a cÃ³
    if "training_results" not in st.session_state:
        st.session_state["training_results"] = []  # LÆ°u káº¿t quáº£ huáº¥n luyá»‡n cá»§a tá»«ng vÃ²ng láº·p
    if "prediction_images" not in st.session_state:
        st.session_state["prediction_images"] = []  # LÆ°u hÃ¬nh áº£nh dá»± Ä‘oÃ¡n vÃ  thÃ´ng tin Ä‘Ãºng/sai cá»§a tá»«ng vÃ²ng láº·p
    if "final_metrics" not in st.session_state:
        st.session_state["final_metrics"] = {}  # LÆ°u Ä‘á»™ chÃ­nh xÃ¡c cuá»‘i cÃ¹ng

    num = 0
    if "X_train" not in st.session_state:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return
    
    X_train, X_val, X_test = [st.session_state[k].reshape(-1, 28 * 28) / 255.0 for k in ["X_train", "X_val", "X_test"]]
    y_train, y_val, y_test = [st.session_state[k] for k in ["y_train", "y_val", "y_test"]]
    
    k_folds = st.slider("Sá»‘ fold cho Cross-Validation:", 3, 10, 5)
    num_layers = st.slider("Sá»‘ lá»›p áº©n:", 1, 20, 2)
    num_neurons = st.slider("Sá»‘ neuron má»—i lá»›p:", 32, 512, 128, 32)
    activation = st.selectbox("HÃ m kÃ­ch hoáº¡t:", ["relu", "sigmoid", "tanh"])
    optimizer = st.selectbox("Optimizer:", ["adam", "sgd", "rmsprop"])
    epochs = st.slider("ğŸ•° Sá»‘ epochs:", min_value=1, max_value=50, value=20, step=1)
    learning_rate = st.slider("âš¡ Tá»‘c Ä‘á»™ há»c (Learning Rate):", min_value=1e-5, max_value=1e-1, value=1e-3, step=1e-5, format="%.5f")

    st.title(f"Chá»n tham sá»‘ cho Pseudo Labelling ")
    labeled_ratio = st.slider("ğŸ“Š Tá»‰ lá»‡ dá»¯ liá»‡u cÃ³ nhÃ£n ban Ä‘áº§u (%):", min_value=1, max_value=20, value=1, step=1)
    max_iterations = st.slider("ğŸ”„ Sá»‘ láº§n láº·p tá»‘i Ä‘a cá»§a Pseudo-Labeling:", min_value=1, max_value=10, value=3, step=1)
    confidence_threshold = st.slider("âœ… NgÆ°á»¡ng tin cáº­y Pseudo Labeling (%):", min_value=50, max_value=99, value=95, step=1) / 100.0

    loss_fn = "sparse_categorical_crossentropy"
    if "experiment_name" not in st.session_state:
        st.session_state["experiment_name"] = "My_Experiment"

    experiment_name = st.text_input("ğŸ”¹ Nháº­p tÃªn Experiment:", st.session_state["experiment_name"], key="experiment_name_input")    

    if experiment_name:
        st.session_state["experiment_name"] = experiment_name

    mlflow.set_experiment(experiment_name)
    st.write(f"âœ… Experiment Name: {experiment_name}")
    
    # Hiá»ƒn thá»‹ káº¿t quáº£ huáº¥n luyá»‡n Ä‘Ã£ lÆ°u (náº¿u cÃ³) khi chuyá»ƒn tab
    if st.session_state["training_results"]:
        st.subheader("Káº¿t quáº£ huáº¥n luyá»‡n trÆ°á»›c Ä‘Ã³:")
        for result in st.session_state["training_results"]:
            st.write(f"**VÃ²ng láº·p {result['iteration']}:**")
            st.write(f"- **GÃ¡n nhÃ£n giáº£ cho {result['num_pseudo_added']} máº«u vá»›i Ä‘á»™ tin cáº­y â‰¥ {confidence_threshold}:**")
            st.write(f"  - Sá»‘ nhÃ£n giáº£ Ä‘Ãºng: {result['correct_pseudo_labels']}")
            st.write(f"  - Sá»‘ nhÃ£n giáº£ sai: {result['incorrect_pseudo_labels']}")
            st.write(f"- **Sá»‘ áº£nh Ä‘Ã£ gÃ¡n nhÃ£n:** {result['total_labeled']}")
            st.write(f"- **Sá»‘ áº£nh chÆ°a gÃ¡n nhÃ£n:** {result['remaining_unlabeled']}")
            st.write(f"- **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test:** {result['test_accuracy']:.4f}")
            # TÃ¬m thÃ´ng tin sá»‘ lÆ°á»£ng nhÃ£n Ä‘Ãºng/sai tÆ°Æ¡ng á»©ng vá»›i vÃ²ng láº·p
            for img_data in st.session_state["prediction_images"]:
                if img_data["iteration"] == result["iteration"]:
                    st.write(f"- **Sá»‘ lÆ°á»£ng nhÃ£n dá»± Ä‘oÃ¡n Ä‘Ãºng (trong 10 áº£nh):** {img_data['correct_predictions']}")
                    st.write(f"- **Sá»‘ lÆ°á»£ng nhÃ£n dá»± Ä‘oÃ¡n sai (trong 10 áº£nh):** {img_data['incorrect_predictions']}")
            st.write("---")

    # Hiá»ƒn thá»‹ hÃ¬nh áº£nh dá»± Ä‘oÃ¡n vÃ  thÃ´ng tin Ä‘Ãºng/sai Ä‘Ã£ lÆ°u (náº¿u cÃ³) khi chuyá»ƒn tab
    if st.session_state["prediction_images"]:
        for img_data in st.session_state["prediction_images"]:
            st.subheader(f"Dá»± Ä‘oÃ¡n 10 áº£nh tá»« táº­p test sau vÃ²ng láº·p {img_data['iteration']}")
            st.pyplot(img_data["figure"])
            st.write(f"- **Sá»‘ lÆ°á»£ng nhÃ£n dá»± Ä‘oÃ¡n Ä‘Ãºng:** {img_data['correct_predictions']}")
            st.write(f"- **Sá»‘ lÆ°á»£ng nhÃ£n dá»± Ä‘oÃ¡n sai:** {img_data['incorrect_predictions']}")

    # Hiá»ƒn thá»‹ Ä‘á»™ chÃ­nh xÃ¡c cuá»‘i cÃ¹ng Ä‘Ã£ lÆ°u (náº¿u cÃ³) khi chuyá»ƒn tab
    if st.session_state["final_metrics"]:
        st.success(f"âœ… Huáº¥n luyá»‡n hoÃ n táº¥t!")
        st.write(f"ğŸ“Š **Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh trÃªn táº­p validation:** {st.session_state['final_metrics']['avg_val_accuracy']:.4f}")
        st.write(f"ğŸ“Š **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test:** {st.session_state['final_metrics']['test_accuracy']:.4f}")
        st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho Experiments Neural_Network vá»›i Name: **Train_{st.session_state['run_name']}**!")
        st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")

    if st.button("ğŸš€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        # Reset káº¿t quáº£ trÆ°á»›c Ä‘Ã³ khi báº¯t Ä‘áº§u huáº¥n luyá»‡n má»›i
        st.session_state["training_results"] = []
        st.session_state["prediction_images"] = []
        st.session_state["final_metrics"] = {}

        if "run_name" not in st.session_state:
            st.session_state["run_name"] = f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}" 
        with st.spinner("Äang huáº¥n luyá»‡n..."):
            mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}")
            mlflow.log_params({
                "num_layers": num_layers,
                "num_neurons": num_neurons,
                "activation": activation,
                "optimizer": optimizer,
                "learning_rate": learning_rate,
                "k_folds": k_folds,
                "epochs": epochs,
                "labeled_ratio": labeled_ratio,
                "max_iterations": max_iterations,
                "confidence_threshold": confidence_threshold
            })

            num_labeled = int(len(X_train) * labeled_ratio / 100)
            labeled_idx = np.random.choice(len(X_train), num_labeled, replace=False)
            unlabeled_idx = np.setdiff1d(np.arange(len(X_train)), labeled_idx)

            X_labeled, y_labeled = X_train[labeled_idx], y_train[labeled_idx]
            X_unlabeled = X_train[unlabeled_idx]
            y_unlabeled_true = y_train[unlabeled_idx]  # Láº¥y nhÃ£n thá»±c táº¿ cá»§a dá»¯ liá»‡u chÆ°a cÃ³ nhÃ£n Ä‘á»ƒ so sÃ¡nh

            total_pseudo_labels = 0  # Tá»•ng sá»‘ nhÃ£n giáº£ Ä‘Æ°á»£c thÃªm vÃ o
            for iteration in range(max_iterations):
                kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
                accuracies, losses = [], []
                training_progress = st.progress(0)
                training_status = st.empty()

                num = 0
                total_steps = k_folds * max_iterations
                for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_labeled, y_labeled)):
                    X_k_train, X_k_val = X_labeled[train_idx], X_labeled[val_idx]
                    y_k_train, y_k_val = y_labeled[train_idx], y_labeled[val_idx]

                    model = keras.Sequential([
                        layers.Input(shape=(X_k_train.shape[1],))
                    ] + [
                        layers.Dense(num_neurons, activation=activation) for _ in range(num_layers)
                    ] + [
                        layers.Dense(10, activation="softmax")
                    ])

                    if optimizer == "adam":
                        opt = keras.optimizers.Adam(learning_rate=learning_rate)
                    elif optimizer == "sgd":
                        opt = keras.optimizers.SGD(learning_rate=learning_rate)
                    else:
                        opt = keras.optimizers.RMSprop(learning_rate=learning_rate)

                    model.compile(optimizer=opt, loss=loss_fn, metrics=["accuracy"])

                    start_time = time.time()
                    history = model.fit(X_k_train, y_k_train, epochs=epochs, validation_data=(X_k_val, y_k_val), verbose=0)
                    elapsed_time = time.time() - start_time

                    accuracies.append(history.history["val_accuracy"][-1])
                    losses.append(history.history["val_loss"][-1])
                    num += 1
                    progress_percent = int((num / k_folds) * 100)

                    training_progress.progress(progress_percent)
                    training_status.text(f"â³ Äang huáº¥n luyá»‡n... {progress_percent}%")

                avg_val_accuracy = np.mean(accuracies)
                avg_val_loss = np.mean(losses)

                mlflow.log_metrics({
                    "avg_val_accuracy": avg_val_accuracy,
                    "avg_val_loss": avg_val_loss,
                    "elapsed_time": elapsed_time
                })
                pseudo_preds = model.predict(X_unlabeled)
                pseudo_labels = np.argmax(pseudo_preds, axis=1)
                confidence_scores = np.max(pseudo_preds, axis=1)
                confident_mask = confidence_scores > confidence_threshold

                num_pseudo_added = np.sum(confident_mask)
                total_pseudo_labels += num_pseudo_added

                # TÃ­nh sá»‘ nhÃ£n giáº£ Ä‘Ãºng vÃ  sai
                pseudo_labels_confident = pseudo_labels[confident_mask]
                y_unlabeled_true_confident = y_unlabeled_true[confident_mask]
                correct_pseudo_labels = np.sum(pseudo_labels_confident == y_unlabeled_true_confident)
                incorrect_pseudo_labels = num_pseudo_added - correct_pseudo_labels

                X_labeled = np.concatenate([X_labeled, X_unlabeled[confident_mask]])
                y_labeled = np.concatenate([y_labeled, pseudo_labels[confident_mask]])
                X_unlabeled = X_unlabeled[~confident_mask]
                y_unlabeled_true = y_unlabeled_true[~confident_mask]  # Cáº­p nháº­t nhÃ£n thá»±c táº¿ cá»§a dá»¯ liá»‡u chÆ°a cÃ³ nhÃ£n

                # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test sau khi gÃ¡n nhÃ£n giáº£
                test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)

                # LÆ°u káº¿t quáº£ huáº¥n luyá»‡n vÃ o session_state
                st.session_state["training_results"].append({
                    "iteration": iteration + 1,
                    "num_pseudo_added": num_pseudo_added,
                    "correct_pseudo_labels": correct_pseudo_labels,
                    "incorrect_pseudo_labels": incorrect_pseudo_labels,
                    "total_labeled": len(X_labeled),
                    "total_pseudo_labels": total_pseudo_labels,
                    "remaining_unlabeled": len(X_unlabeled),
                    "test_accuracy": test_accuracy
                })

                st.write(f"**VÃ²ng láº·p {iteration+1}:**")
                st.write(f"- **GÃ¡n nhÃ£n giáº£ cho {num_pseudo_added} máº«u vá»›i Ä‘á»™ tin cáº­y â‰¥ {confidence_threshold}:**")
                st.write(f"  - Sá»‘ nhÃ£n giáº£ Ä‘Ãºng: {correct_pseudo_labels}")
                st.write(f"  - Sá»‘ nhÃ£n giáº£ sai: {incorrect_pseudo_labels}")
                st.write(f"- **Sá»‘ áº£nh Ä‘Ã£ gÃ¡n nhÃ£n:** {len(X_labeled)}")
                st.write(f"- **Sá»‘ áº£nh chÆ°a gÃ¡n nhÃ£n:** {len(X_unlabeled)}")
                st.write(f"- **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test:** {test_accuracy:.4f}")

                # Dá»± Ä‘oÃ¡n vÃ  hiá»ƒn thá»‹ 10 áº£nh tá»« táº­p test
                st.subheader(f"Dá»± Ä‘oÃ¡n 10 áº£nh tá»« táº­p test sau vÃ²ng láº·p {iteration+1}")
                indices = np.random.choice(len(X_test), 10, replace=False)
                X_test_samples = X_test[indices]
                y_test_samples = y_test[indices]

                predictions = model.predict(X_test_samples)
                predicted_labels = np.argmax(predictions, axis=1)

                # TÃ­nh sá»‘ lÆ°á»£ng nhÃ£n dá»± Ä‘oÃ¡n Ä‘Ãºng vÃ  sai
                correct_predictions = np.sum(predicted_labels == y_test_samples)
                incorrect_predictions = len(y_test_samples) - correct_predictions

                # Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng nhÃ£n dá»± Ä‘oÃ¡n Ä‘Ãºng vÃ  sai trong káº¿t quáº£ vÃ²ng láº·p
                st.write(f"- **Sá»‘ lÆ°á»£ng nhÃ£n dá»± Ä‘oÃ¡n Ä‘Ãºng (trong 10 áº£nh):** {correct_predictions}")
                st.write(f"- **Sá»‘ lÆ°á»£ng nhÃ£n dá»± Ä‘oÃ¡n sai (trong 10 áº£nh):** {incorrect_predictions}")
                st.write("---")

                fig, axes = plt.subplots(2, 5, figsize=(15, 6))
                axes = axes.ravel()
                for i in range(10):
                    axes[i].imshow(X_test_samples[i].reshape(28, 28), cmap='gray')
                    axes[i].set_title(f"Thá»±c táº¿: {y_test_samples[i]}\nDá»± Ä‘oÃ¡n: {predicted_labels[i]}")
                    axes[i].axis('off')
                plt.tight_layout()

                # LÆ°u hÃ¬nh áº£nh dá»± Ä‘oÃ¡n vÃ  thÃ´ng tin Ä‘Ãºng/sai vÃ o session_state
                st.session_state["prediction_images"].append({
                    "iteration": iteration + 1,
                    "figure": fig,
                    "correct_predictions": correct_predictions,
                    "incorrect_predictions": incorrect_predictions
                })
                st.pyplot(fig)

                # LÆ°u Ä‘á»™ chÃ­nh xÃ¡c vÃ o MLflow Ä‘á»ƒ theo dÃµi
                mlflow.log_metrics({
                    f"test_accuracy_iter_{iteration+1}": test_accuracy,
                    f"correct_predictions_iter_{iteration+1}": correct_predictions,
                    f"incorrect_predictions_iter_{iteration+1}": incorrect_predictions,
                    f"correct_pseudo_labels_iter_{iteration+1}": correct_pseudo_labels,
                    f"incorrect_pseudo_labels_iter_{iteration+1}": incorrect_pseudo_labels
                })
                if len(X_unlabeled) == 0:
                    break

            test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
            mlflow.log_metrics({"test_accuracy": test_accuracy, "test_loss": test_loss})

            # LÆ°u Ä‘á»™ chÃ­nh xÃ¡c cuá»‘i cÃ¹ng vÃ o session_state
            st.session_state["final_metrics"] = {
                "avg_val_accuracy": avg_val_accuracy,
                "test_accuracy": test_accuracy
            }

            mlflow.end_run()
            st.session_state["trained_model"] = model

            # HoÃ n thÃ nh tiáº¿n trÃ¬nh
            training_progress.progress(100)
            training_status.text("âœ… Huáº¥n luyá»‡n hoÃ n táº¥t!")

            st.success(f"âœ… Huáº¥n luyá»‡n hoÃ n táº¥t!")
    
            st.write(f"ğŸ“Š **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test:** {test_accuracy:.4f}")
       
            st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho Experiments Neural_Network vá»›i Name: **Train_{st.session_state['run_name']}**!")
            st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")
# Xá»­ lÃ½ áº£nh tá»« canvas
def preprocess_canvas_image(canvas_result):
    """Chuyá»ƒn Ä‘á»•i áº£nh tá»« canvas sang Ä‘á»‹nh dáº¡ng phÃ¹ há»£p Ä‘á»ƒ dá»± Ä‘oÃ¡n."""
    if canvas_result.image_data is None:
        return None
    img = canvas_result.image_data[:, :, :3]  # Chá»‰ láº¥y 3 kÃªnh RGB
    img = Image.fromarray(img).convert("L").resize((28, 28))  # Chuyá»ƒn sang grayscale, resize vá» 28x28
    img = np.array(img) / 255.0  # Chuáº©n hÃ³a vá» [0,1]
    img = img.reshape(1, -1)  # ÄÆ°a vá» dáº¡ng vector giá»‘ng nhÆ° trong `thi_nghiem()`
    return img

# HÃ m dá»± Ä‘oÃ¡n
def du_doan():
    st.header("âœï¸ Váº½ sá»‘ Ä‘á»ƒ dá»± Ä‘oÃ¡n")

    # ğŸ“¥ Load mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    if "trained_model" in st.session_state:
        model = st.session_state["trained_model"]
        st.success("âœ… ÄÃ£ sá»­ dá»¥ng mÃ´ hÃ¬nh vá»«a huáº¥n luyá»‡n!")
    else:
        st.error("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh! HÃ£y huáº¥n luyá»‡n trÆ°á»›c.")


    # ğŸ†• Cáº­p nháº­t key cho canvas khi nháº¥n "Táº£i láº¡i"
    if "key_value" not in st.session_state:
        st.session_state.key_value = str(random.randint(0, 1000000))  

    if st.button("ğŸ”„ Táº£i láº¡i náº¿u khÃ´ng tháº¥y canvas"):
        st.session_state.key_value = str(random.randint(0, 1000000))  

    # âœï¸ Váº½ sá»‘
    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key=st.session_state.key_value,
        update_streamlit=True
    )

    if st.button("Dá»± Ä‘oÃ¡n sá»‘"):
        img = preprocess_canvas_image(canvas_result)

        if img is not None:
            st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="áº¢nh sau xá»­ lÃ½", width=100)

            # Dá»± Ä‘oÃ¡n sá»‘
            prediction = model.predict(img)
            predicted_number = np.argmax(prediction, axis=1)[0]
            max_confidence = np.max(prediction)

            st.subheader(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: {predicted_number}")
            st.write(f"ğŸ“Š Má»©c Ä‘á»™ tin cáº­y: {max_confidence:.2%}")

            # Hiá»ƒn thá»‹ báº£ng confidence score
            prob_df = pd.DataFrame(prediction.reshape(1, -1), columns=[str(i) for i in range(10)]).T
            prob_df.columns = ["Má»©c Ä‘á»™ tin cáº­y"]
            st.bar_chart(prob_df)

        else:
            st.error("âš ï¸ HÃ£y váº½ má»™t sá»‘ trÆ°á»›c khi báº¥m Dá»± Ä‘oÃ¡n!")

from datetime import datetime

def show_experiment_selector():
    st.title("ğŸ“Š MLflow Experiments - DAGsHub")

    # Láº¥y danh sÃ¡ch táº¥t cáº£ experiments
    experiments = mlflow.search_experiments()
    experiment_names = [exp.name for exp in experiments]    
    # TÃ¬m experiment theo tÃªn
    
    selected_experiment_name = st.selectbox("ğŸ” Chá»n má»™t Experiment:", experiment_names)

    if not selected_experiment_name:
        st.error(f"âŒ Experiment '{selected_experiment_name}' khÃ´ng tá»“n táº¡i!")
        return
    selected_experiment = next((exp for exp in experiments if exp.name == selected_experiment_name), None)

    if not selected_experiment:
        st.error("âŒ KhÃ´ng tÃ¬m tháº¥y experiment trong danh sÃ¡ch.")
        return
    st.subheader(f"ğŸ“Œ Experiment: {selected_experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tráº¡ng thÃ¡i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**Vá»‹ trÃ­ lÆ°u trá»¯:** {selected_experiment.artifact_location}")

    # Láº¥y danh sÃ¡ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return

    st.write("### ğŸƒâ€â™‚ï¸ CÃ¡c Runs gáº§n Ä‘Ã¢y:")

    # Láº¥y danh sÃ¡ch run_name tá»« params
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_params = mlflow.get_run(run_id).data.params
        run_name = run_params.get("run_name", f"Run {run_id[:8]}")  # Náº¿u khÃ´ng cÃ³ tÃªn, láº¥y 8 kÃ½ tá»± Ä‘áº§u cá»§a ID
        run_info.append((run_name, run_id))
    # Äáº£m báº£o danh sÃ¡ch run_info Ä‘Æ°á»£c sáº¯p xáº¿p theo thá»i gian cháº¡y gáº§n nháº¥t
    run_info.sort(key=lambda x: mlflow.get_run(x[1]).info.start_time, reverse=True)
    
    # Táº¡o dictionary Ä‘á»ƒ map run_name -> run_id
    # Láº¥y run gáº§n nháº¥t
    if run_info:
        latest_run_name, latest_run_id = run_info[0]  # Chá»n run má»›i nháº¥t
        selected_run_name = latest_run_name
        selected_run_id = latest_run_id
    else:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return

    # Hiá»ƒn thá»‹ thÃ´ng tin chi tiáº¿t cá»§a run Ä‘Æ°á»£c chá»n
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"ğŸ“Œ ThÃ´ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
        start_time_ms = selected_run.info.start_time  # Thá»i gian lÆ°u dÆ°á»›i dáº¡ng milliseconds

        # Chuyá»ƒn sang Ä‘á»‹nh dáº¡ng ngÃ y giá» dá»… Ä‘á»c
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "KhÃ´ng cÃ³ thÃ´ng tin"

        st.write(f"**Thá»i gian cháº¡y:** {start_time}")

        # Hiá»ƒn thá»‹ thÃ´ng sá»‘ Ä‘Ã£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### âš™ï¸ Parameters:")
            st.json(params)

        if metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(metrics)

        # Kiá»ƒm tra vÃ  hiá»ƒn thá»‹ dataset artifact
        dataset_uri = f"{selected_experiment.artifact_location}/{selected_run_id}/artifacts/dataset.csv" 
        try:
            mlflow.artifacts.download_artifacts(dataset_uri)
            st.write("### ğŸ“‚ Dataset:")
            st.write(f"ğŸ“¥ [Táº£i dataset]({dataset_uri})")
        except Exception as e:
            st.warning("âš  KhÃ´ng tÃ¬m tháº¥y dataset.csv trong artifacts.")
# HÃ m lÃ½ thuyáº¿t Neural Network
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt

# HÃ m lÃ½ LÃ½ thuyáº¿t vá» Pseudo Labelling
import streamlit as st

def explain_Pseudo_Labelling():
    st.markdown("## ğŸ“š LÃ½ thuyáº¿t vá» Pseudo Labelling")

    # Giá»›i thiá»‡u tá»•ng quan
    st.markdown("""
    **Pseudo Labelling** (GÃ¡n nhÃ£n giáº£) lÃ  má»™t ká»¹ thuáº­t há»c bÃ¡n giÃ¡m sÃ¡t (semi-supervised learning) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº­n dá»¥ng dá»¯ liá»‡u chÆ°a cÃ³ nhÃ£n (unlabeled data) trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh há»c mÃ¡y. Ã tÆ°á»Ÿng chÃ­nh lÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t táº­p dá»¯ liá»‡u cÃ³ nhÃ£n nhá» Ä‘á»ƒ dá»± Ä‘oÃ¡n nhÃ£n cho dá»¯ liá»‡u chÆ°a cÃ³ nhÃ£n, sau Ä‘Ã³ sá»­ dá»¥ng cÃ¡c nhÃ£n giáº£ nÃ y Ä‘á»ƒ má»Ÿ rá»™ng táº­p huáº¥n luyá»‡n vÃ  tiáº¿p tá»¥c huáº¥n luyá»‡n mÃ´ hÃ¬nh.
    """)

    # Khi nÃ o sá»­ dá»¥ng Pseudo Labelling
    st.subheader("ğŸ” Khi nÃ o sá»­ dá»¥ng Pseudo Labelling?")
    st.markdown("""
    Pseudo Labelling thÆ°á»ng Ä‘Æ°á»£c Ã¡p dá»¥ng trong cÃ¡c tÃ¬nh huá»‘ng sau:
    - **Dá»¯ liá»‡u cÃ³ nhÃ£n háº¡n cháº¿:** Khi báº¡n chá»‰ cÃ³ má»™t lÆ°á»£ng nhá» dá»¯ liá»‡u cÃ³ nhÃ£n (labeled data) nhÆ°ng cÃ³ ráº¥t nhiá»u dá»¯ liá»‡u chÆ°a cÃ³ nhÃ£n (unlabeled data).
    - **Dá»¯ liá»‡u chÆ°a nhÃ£n cÃ³ giÃ¡ trá»‹:** Dá»¯ liá»‡u chÆ°a nhÃ£n cÃ³ thá»ƒ cung cáº¥p thÃ´ng tin bá»• sung Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh.
    - **MÃ´ hÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c ban Ä‘áº§u tá»‘t:** MÃ´ hÃ¬nh ban Ä‘áº§u (huáº¥n luyá»‡n trÃªn táº­p dá»¯ liá»‡u cÃ³ nhÃ£n nhá») cáº§n cÃ³ kháº£ nÄƒng dá»± Ä‘oÃ¡n nhÃ£n giáº£ Ä‘á»§ Ä‘Ã¡ng tin cáº­y.
    """)

    # CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Pseudo Labelling
    st.subheader("âš™ï¸ CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Pseudo Labelling")
    st.markdown("""
    Quy trÃ¬nh cá»§a Pseudo Labelling thÆ°á»ng bao gá»“m cÃ¡c bÆ°á»›c sau:
    1. **Huáº¥n luyá»‡n ban Ä‘áº§u:**
       - Sá»­ dá»¥ng má»™t táº­p dá»¯ liá»‡u nhá» cÃ³ nhÃ£n (labeled data) Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh ban Ä‘áº§u.
       - VÃ­ dá»¥: Vá»›i táº­p dá»¯ liá»‡u MNIST, báº¡n cÃ³ thá»ƒ láº¥y 1% dá»¯ liá»‡u cÃ³ nhÃ£n (khoáº£ng 600 áº£nh tá»« 60,000 áº£nh train).
    2. **Dá»± Ä‘oÃ¡n nhÃ£n giáº£:**
       - Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n Ä‘á»ƒ dá»± Ä‘oÃ¡n nhÃ£n cho dá»¯ liá»‡u chÆ°a cÃ³ nhÃ£n.
       - Káº¿t quáº£ dá»± Ä‘oÃ¡n thÆ°á»ng lÃ  xÃ¡c suáº¥t cho tá»«ng lá»›p (vÃ­ dá»¥: [0.1, 0.85, 0.05] cho 3 lá»›p).
    3. **Lá»c dá»¯ liá»‡u tin cáº­y:**
       - Chá»n cÃ¡c máº«u cÃ³ Ä‘á»™ tin cáº­y cao (dá»±a trÃªn ngÆ°á»¡ng xÃ¡c suáº¥t, vÃ­ dá»¥: xÃ¡c suáº¥t lá»›n nháº¥t â‰¥ 0.95).
       - VÃ­ dá»¥: Náº¿u xÃ¡c suáº¥t dá»± Ä‘oÃ¡n cho lá»›p "5" lÃ  0.98 (> 0.95), gÃ¡n nhÃ£n giáº£ "5" cho máº«u Ä‘Ã³.
    4. **Má»Ÿ rá»™ng táº­p huáº¥n luyá»‡n:**
       - ThÃªm cÃ¡c máº«u vá»«a Ä‘Æ°á»£c gÃ¡n nhÃ£n giáº£ vÃ o táº­p dá»¯ liá»‡u cÃ³ nhÃ£n ban Ä‘áº§u.
    5. **Láº·p láº¡i:**
       - Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u má»›i (gá»“m dá»¯ liá»‡u cÃ³ nhÃ£n ban Ä‘áº§u + dá»¯ liá»‡u gÃ¡n nhÃ£n giáº£).
       - Láº·p láº¡i quÃ¡ trÃ¬nh cho Ä‘áº¿n khi:
         - Háº¿t dá»¯ liá»‡u chÆ°a nhÃ£n.
         - Äáº¡t sá»‘ láº§n láº·p tá»‘i Ä‘a.
         - Hiá»‡u suáº¥t mÃ´ hÃ¬nh khÃ´ng cáº£i thiá»‡n thÃªm.
    """)

    # Æ¯u Ä‘iá»ƒm vÃ  nhÆ°á»£c Ä‘iá»ƒm
    st.subheader("âœ… Æ¯u Ä‘iá»ƒm vÃ  âš ï¸ NhÆ°á»£c Ä‘iá»ƒm")
    st.markdown("""
    ### Æ¯u Ä‘iá»ƒm:
    - **Táº­n dá»¥ng dá»¯ liá»‡u chÆ°a nhÃ£n:** GiÃºp cáº£i thiá»‡n hiá»‡u suáº¥t mÃ´ hÃ¬nh khi dá»¯ liá»‡u cÃ³ nhÃ£n háº¡n cháº¿.
    - **ÄÆ¡n giáº£n vÃ  hiá»‡u quáº£:** Dá»… triá»ƒn khai, khÃ´ng yÃªu cáº§u cÃ¡c ká»¹ thuáº­t phá»©c táº¡p.
    - **TÄƒng Ä‘á»™ chÃ­nh xÃ¡c:** Náº¿u nhÃ£n giáº£ Ä‘Æ°á»£c dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c, mÃ´ hÃ¬nh sáº½ há»c Ä‘Æ°á»£c tá»« dá»¯ liá»‡u má»›i vÃ  cáº£i thiá»‡n hiá»‡u suáº¥t.

    ### NhÆ°á»£c Ä‘iá»ƒm:
    - **Phá»¥ thuá»™c vÃ o mÃ´ hÃ¬nh ban Ä‘áº§u:** Náº¿u mÃ´ hÃ¬nh ban Ä‘áº§u dá»± Ä‘oÃ¡n sai nhiá»u, nhÃ£n giáº£ sáº½ khÃ´ng chÃ­nh xÃ¡c, dáº«n Ä‘áº¿n hiá»‡u á»©ng "lá»—i tÃ­ch lÅ©y" (error propagation).
    - **NgÆ°á»¡ng lá»±a chá»n:** Viá»‡c chá»n ngÆ°á»¡ng xÃ¡c suáº¥t (threshold) lÃ  má»™t thÃ¡ch thá»©c. NgÆ°á»¡ng quÃ¡ cao cÃ³ thá»ƒ bá» sÃ³t nhiá»u máº«u, ngÆ°á»¡ng quÃ¡ tháº¥p cÃ³ thá»ƒ gÃ¡n nhÃ£n sai.
    - **Tá»‘n tÃ i nguyÃªn:** QuÃ¡ trÃ¬nh láº·p láº¡i vÃ  huáº¥n luyá»‡n nhiá»u láº§n cÃ³ thá»ƒ tá»‘n thá»i gian vÃ  tÃ i nguyÃªn tÃ­nh toÃ¡n.
    """)

    # á»¨ng dá»¥ng thá»±c táº¿
    st.subheader("ğŸŒŸ á»¨ng dá»¥ng thá»±c táº¿")
    st.markdown("""
    Pseudo Labelling thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c bÃ i toÃ¡n sau:
    - **PhÃ¢n loáº¡i áº£nh:** VÃ­ dá»¥, trÃªn táº­p dá»¯ liá»‡u MNIST (chá»¯ sá»‘ viáº¿t tay), nÆ¡i dá»¯ liá»‡u cÃ³ nhÃ£n Ã­t nhÆ°ng dá»¯ liá»‡u chÆ°a nhÃ£n dá»“i dÃ o.
    - **Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP):** GÃ¡n nhÃ£n cho vÄƒn báº£n chÆ°a cÃ³ nhÃ£n (vÃ­ dá»¥: phÃ¢n loáº¡i cáº£m xÃºc, nháº­n diá»‡n thá»±c thá»ƒ).
    - **Y há»c:** Sá»­ dá»¥ng dá»¯ liá»‡u y táº¿ chÆ°a cÃ³ nhÃ£n Ä‘á»ƒ cáº£i thiá»‡n mÃ´ hÃ¬nh cháº©n Ä‘oÃ¡n bá»‡nh.
    """)

    # VÃ­ dá»¥ minh há»a
    st.subheader("ğŸ“Š VÃ­ dá»¥ minh há»a trÃªn MNIST")
    st.markdown("""
    Giáº£ sá»­ báº¡n cÃ³ táº­p dá»¯ liá»‡u MNIST vá»›i 60,000 áº£nh train (cÃ³ nhÃ£n) vÃ  10,000 áº£nh test:
    1. Láº¥y 1% dá»¯ liá»‡u cÃ³ nhÃ£n (600 áº£nh, 60 áº£nh má»—i lá»›p tá»« 0-9).
    2. Huáº¥n luyá»‡n má»™t Neural Network trÃªn 600 áº£nh nÃ y.
    3. Dá»± Ä‘oÃ¡n nhÃ£n cho 59,400 áº£nh cÃ²n láº¡i (99% dá»¯ liá»‡u train).
    4. Chá»n ngÆ°á»¡ng xÃ¡c suáº¥t lÃ  0.95:
       - Náº¿u má»™t áº£nh cÃ³ xÃ¡c suáº¥t cao nháº¥t â‰¥ 0.95, gÃ¡n nhÃ£n giáº£ cho áº£nh Ä‘Ã³.
       - VÃ­ dá»¥: Dá»± Ä‘oÃ¡n [0.01, 0.02, 0.95, ...] â†’ GÃ¡n nhÃ£n "2".
    5. ThÃªm cÃ¡c áº£nh Ä‘Æ°á»£c gÃ¡n nhÃ£n giáº£ vÃ o táº­p huáº¥n luyá»‡n (600 áº£nh ban Ä‘áº§u + áº£nh má»›i).
    6. Láº·p láº¡i quÃ¡ trÃ¬nh cho Ä‘áº¿n khi gÃ¡n nhÃ£n háº¿t 60,000 áº£nh hoáº·c Ä‘áº¡t sá»‘ láº§n láº·p tá»‘i Ä‘a.
    """)

    # Káº¿t luáº­n
    st.subheader("ğŸ¯ Káº¿t luáº­n")
    st.markdown("""
    Pseudo Labelling lÃ  má»™t ká»¹ thuáº­t máº¡nh máº½ trong há»c bÃ¡n giÃ¡m sÃ¡t, giÃºp táº­n dá»¥ng dá»¯ liá»‡u chÆ°a cÃ³ nhÃ£n Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t mÃ´ hÃ¬nh. Tuy nhiÃªn, cáº§n cáº©n tháº­n khi chá»n ngÆ°á»¡ng xÃ¡c suáº¥t vÃ  Ä‘áº£m báº£o mÃ´ hÃ¬nh ban Ä‘áº§u cÃ³ Ä‘á»™ chÃ­nh xÃ¡c Ä‘á»§ tá»‘t Ä‘á»ƒ trÃ¡nh lá»—i tÃ­ch lÅ©y. Ká»¹ thuáº­t nÃ y Ä‘áº·c biá»‡t há»¯u Ã­ch trong cÃ¡c bÃ i toÃ¡n thá»±c táº¿ nhÆ° phÃ¢n loáº¡i áº£nh (MNIST) hoáº·c xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn.
    """)

def show_prediction_table():
    st.table({
        "áº¢nh": ["áº¢nh 1", "áº¢nh 2", "áº¢nh 3", "áº¢nh 4", "áº¢nh 5"],
        "Dá»± Ä‘oÃ¡n": [7, 2, 3, 5, 8],
        "XÃ¡c suáº¥t": [0.98, 0.85, 0.96, 0.88, 0.97],
        "GÃ¡n nhÃ£n?": ["âœ…", "âŒ", "âœ…", "âŒ", "âœ…"]
    })
# HÃ m hiá»ƒn thá»‹ thÃ´ng tin vá» MNIST
def data():
    st.title("KhÃ¡m PhÃ¡ Bá»™ Dá»¯ Liá»‡u MNIST")
   

    st.markdown("""
        <div style="background-color: #F0F8FF; padding: 20px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            <h2 style="color: #32CD32; font-size: 32px;">ğŸ“Š Tá»•ng Quan Vá» MNIST</h2>
            <p style="font-size: 20px; color: #333; text-align: justify;">
                MNIST (Modified National Institute of Standards and Technology) lÃ  bá»™ dá»¯ liá»‡u <b>huyá»n thoáº¡i</b> 
                trong nháº­n diá»‡n chá»¯ sá»‘ viáº¿t tay, vá»›i <b>70.000 áº£nh</b> (60.000 train, 10.000 test), má»—i áº£nh 
                cÃ³ kÃ­ch thÆ°á»›c <b>28x28 pixel</b> grayscale.
            </p>
        </div>
    """, unsafe_allow_html=True)

    X, y = load_mnist_data()
    fig, ax = plt.subplots(1, 5, figsize=(15, 3))
    for i in range(5):
        ax[i].imshow(X[i].reshape(28, 28), cmap='gray')
        ax[i].axis('off')
        ax[i].set_title(f"NhÃ£n: {int(y[i])}")
    # Sá»­ dá»¥ng st.pyplot() thay vÃ¬ st.image()
    st.pyplot(fig)

    st.markdown("""
        <h2 style="color: #FF4500; font-size: 32px;">ğŸŒ á»¨ng Dá»¥ng Thá»±c Táº¿</h2>
        <div style="display: flex; gap: 20px;">
            <div style="background-color: #ECF0F1; padding: 15px; border-radius: 10px; flex: 1;">
                <p style="font-size: 20px; color: #2E86C1;">Nháº­n diá»‡n sá»‘ trÃªn hÃ³a Ä‘Æ¡n.</p>
            </div>
            <div style="background-color: #ECF0F1; padding: 15px; border-radius: 10px; flex: 1;">
                <p style="font-size: 20px; color: #2E86C1;">Xá»­ lÃ½ mÃ£ bÆ°u kiá»‡n.</p>
            </div>
        </div>
    """, unsafe_allow_html=True)

    st.markdown("<h2 style='color: #8A2BE2; font-size: 32px;'>ğŸ† Hiá»‡u Suáº¥t MÃ´ HÃ¬nh</h2>", unsafe_allow_html=True)
    data = {"MÃ´ hÃ¬nh": ["Neural Network", "SVM", "CNN"], "Äá»™ chÃ­nh xÃ¡c": ["0.98", "0.97", "0.99"]}
    df = pd.DataFrame(data)
    st.table(df.style.set_properties(**{'background-color': '#F5F5F5', 'border': '1px solid #DDD', 'text-align': 'center', 'font-size': '18px'}).set_table_styles([{'selector': 'th', 'props': [('background-color', '#3498DB'), ('color', 'white')]}]))
def pseudo_labelling():
    st.title("Phá»¥ GiÃºp PhÃ¢n Lï¿½ï¿½p")
    st.subheader("Phá»¥ giÃºp Neural Network phÃ¢n lï¿½ï¿½p dá»¯ liá»‡u MNIST")
def Classification():
    if "mlflow_initialized" not in st.session_state:
        DAGSHUB_MLFLOW_URI = "https://dagshub.com/PTToan250303/Linear_replication.mlflow"
        mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
        st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
        os.environ["MLFLOW_TRACKING_USERNAME"] = "PTToan250303"
        os.environ["MLFLOW_TRACKING_PASSWORD"] = "5ca8caf353d564c358852da97c7487e64fc30a73"
        mlflow.set_experiment("Semi_supervised_Classification")
    st.markdown("""
        <style>
        .title { font-size: 48px; font-weight: bold; text-align: center; color: #4682B4; margin-top: 50px; }
        .subtitle { font-size: 24px; text-align: center; color: #4A4A4A; }
        hr { border: 1px solid #ddd; }
        </style>
        <div class="title">MNIST Semi supervised App</div>
        <hr>
    """, unsafe_allow_html=True)

    tab1, tab2, tab3, tab4, tab5,tab6 = st.tabs(["ğŸ“˜ LÃ½ thuyáº¿t Neural Network", "ğŸ“˜ Data", "âš™ï¸ Huáº¥n luyá»‡n", "ğŸ”¢ Dá»± Ä‘oÃ¡n", "ğŸ”¥ Mlflow","ğŸ¯ Pseudo Labelling"])

    with tab1:
        explain_Pseudo_Labelling()
    with tab2:
        data()
    with tab3:
        split_data()
        train()
    with tab4:
        du_doan()
    with tab5:
        show_experiment_selector()
    with tab6:
        pseudo_labelling()

if __name__ == "__main__":
   Classification()