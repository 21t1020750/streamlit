import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
from PIL import Image
import joblib
import os
import mlflow
from mlflow.tracking import MlflowClient
import time
from datetime import datetime
from sklearn.preprocessing import StandardScaler

# HÃ m chuáº©n hÃ³a dá»¯ liá»‡u (giá»¯ nguyÃªn)
@st.cache_data
def standardize_data(X, fit=True, _scaler=None):
    if fit or _scaler is None:
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        return X_scaled, scaler
    else:
        return _scaler.transform(X), _scaler

# HÃ m táº£i dá»¯ liá»‡u MNIST (giá»¯ nguyÃªn)
def load_mnist_data():
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
    return X, y

# HÃ m chia dá»¯ liá»‡u (giá»¯ nguyÃªn)
def split_data():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")
    X, y = load_mnist_data()
    total_samples = X.shape[0]
    num_classes = len(np.unique(y))

    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False  

    num_samples = st.slider("ğŸ“Œ Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", 1000, total_samples - num_classes, 10000)
    test_size_percent = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Test", 10, 80, 10)
    test_size = test_size_percent / 100
    remaining_size = 100 - test_size_percent
    val_size_percent = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Validation (trong pháº§n Train)", 0, min(80, remaining_size), 0)
    val_size = val_size_percent / 100

    test_samples = int(num_samples * test_size)
    train_val_samples = num_samples - test_samples
    val_samples = int(train_val_samples * (val_size_percent / remaining_size)) if val_size_percent > 0 else 0

    if test_samples < num_classes or (val_samples < num_classes and val_size_percent > 0):
        st.error(f"âŒ Sá»‘ lÆ°á»£ng máº«u trong táº­p Test hoáº·c Validation pháº£i lá»›n hÆ¡n hoáº·c báº±ng sá»‘ lá»›p ({num_classes}).")
        return

    train_percent = remaining_size - val_size_percent
    if train_percent < 30:
        st.warning(f"âš ï¸ Tá»· lá»‡ Train chá»‰ cÃ²n {train_percent}%! Äiá»u nÃ y cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u suáº¥t mÃ´ hÃ¬nh.")

    st.write(f"ğŸ“Œ **Tá»· lá»‡ phÃ¢n chia:** Test={test_size_percent}%, Validation={val_size_percent}%, Train={train_percent}%")

    if st.session_state.data_split_done:
        if st.button("ğŸ”„ Reset & Chia láº¡i"):
            st.session_state.data_split_done = False
            st.rerun()

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        st.session_state.data_split_done = True
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, stratify=y, random_state=42)
        X_train_full, X_test, y_train_full, y_test = train_test_split(X_selected, y_selected, test_size=test_size, stratify=y_selected, random_state=42)

        if val_size_percent > 0:
            X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=val_size, stratify=y_train_full, random_state=42)
        else:
            X_train, X_val, y_train, y_val = X_train_full, np.array([]), y_train_full, np.array([])

        X_train = X_train / 255.0
        X_test = X_test / 255.0
        X_val = X_val / 255.0 if val_size_percent > 0 else X_val

        st.session_state.total_samples = num_samples
        st.session_state.X_train = X_train
        st.session_state.X_val = X_val
        st.session_state.X_test = X_test
        st.session_state.y_train = y_train
        st.session_state.y_val = y_val
        st.session_state.y_test = y_test
        st.session_state.test_size = X_test.shape[0]
        st.session_state.val_size = X_val.shape[0] if val_size_percent > 0 else 0
        st.session_state.train_size = X_train.shape[0]

        summary_df = pd.DataFrame({
            "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"],
            "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_val.shape[0] if val_size_percent > 0 else 0, X_test.shape[0]]
        })
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia vÃ  chuáº©n hÃ³a thÃ nh cÃ´ng!")
        st.table(summary_df)

    elif st.session_state.data_split_done:
        st.info("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia. Nháº¥n 'Reset & Chia láº¡i' Ä‘á»ƒ Ä‘iá»u chá»‰nh.")
        summary_df = pd.DataFrame({
            "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"],
            "Sá»‘ lÆ°á»£ng máº«u": [st.session_state.train_size, st.session_state.val_size, st.session_state.test_size]
        })
        st.table(summary_df)

# HÃ m huáº¥n luyá»‡n mÃ´ hÃ¬nh Neural Network (Ä‘Ã£ sá»­a vá»›i key duy nháº¥t)
def train():
    if "X_train" not in st.session_state:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! Vui lÃ²ng quay láº¡i bÆ°á»›c chia dá»¯ liá»‡u trÆ°á»›c.")
        st.button("ğŸ”™ Quay láº¡i bÆ°á»›c chia dá»¯ liá»‡u", on_click=lambda: st.session_state.update({"page": "data_split"}))
        return

    X_train = st.session_state.X_train
    X_val = st.session_state.X_val
    X_test = st.session_state.X_test
    y_train = st.session_state.y_train
    y_val = st.session_state.y_val
    y_test = st.session_state.y_test

    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh Neural Network & Huáº¥n luyá»‡n")
    hidden_layer_sizes = st.slider("Hidden Layer Sizes", 10, 200, (100,), step=10, key="train_hidden_layer_sizes")
    activation = st.selectbox("Activation Function", ["relu", "tanh"], key="train_activation")
    learning_rate_init = st.slider("Learning Rate", 0.001, 0.1, 0.01, step=0.001, key="train_learning_rate")
    max_iter = st.slider("Max Iterations", 100, 1000, 500, step=100, key="train_max_iter")

    model = MLPClassifier(
        hidden_layer_sizes=hidden_layer_sizes,
        activation=activation,
        learning_rate_init=learning_rate_init,
        max_iter=max_iter,
        random_state=42
    )

    n_folds = st.slider("Chá»n sá»‘ folds (KFold Cross-Validation):", min_value=2, max_value=10, value=5, key="train_n_folds")

    if "experiment_name" not in st.session_state:
        st.session_state["experiment_name"] = "Neural_Network_Experiment"

    experiment_name = st.text_input("ğŸ”¹ Nháº­p tÃªn Experiment:", st.session_state["experiment_name"], key="train_experiment_name")

    if experiment_name:
        st.session_state["experiment_name"] = experiment_name

    mlflow.set_experiment(experiment_name)
    st.write(f"âœ… Experiment Name: {experiment_name}")

    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        progress_bar = st.progress(0)
        status_text = st.empty()
        st.session_state["run_name"] = f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        with mlflow.start_run(run_name=f"Train_{st.session_state['run_name']}"):
            try:
                status_text.text("ğŸ”„ Ghi log tham sá»‘ vÃ o MLflow...")
                progress_bar.progress(10)
                mlflow.log_param("test_size", st.session_state.get("test_size", 0))
                mlflow.log_param("val_size", st.session_state.get("val_size", 0))
                mlflow.log_param("train_size", st.session_state.get("train_size", 0))
                mlflow.log_param("num_samples", st.session_state.get("total_samples", 0))

                status_text.text("â³ Äang cháº¡y Cross-Validation...")
                progress_bar.progress(40)
                cv_scores = cross_val_score(model, X_train, y_train, cv=n_folds, n_jobs=-1)
                mean_cv_score = cv_scores.mean()
                std_cv_score = cv_scores.std()

                st.success(f"ğŸ“Š **Cross-Validation Accuracy**: {mean_cv_score:.4f} Â± {std_cv_score:.4f}")

                status_text.text("â³ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh...")
                progress_bar.progress(70)
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                acc = accuracy_score(y_test, y_pred)

                st.success(f"âœ… Äá»™ chÃ­nh xÃ¡c trÃªn test set: {acc:.4f}")

                status_text.text("ğŸ”„ Ghi log káº¿t quáº£ vÃ o MLflow...")
                progress_bar.progress(90)
                mlflow.log_param("model", "Neural_Network")
                mlflow.log_param("hidden_layer_sizes", hidden_layer_sizes)
                mlflow.log_param("activation", activation)
                mlflow.log_param("learning_rate_init", learning_rate_init)
                mlflow.log_param("max_iter", max_iter)
                mlflow.log_metric("test_accuracy", acc)
                mlflow.log_metric("cv_accuracy_mean", mean_cv_score)
                mlflow.log_metric("cv_accuracy_std", std_cv_score)
                mlflow.sklearn.log_model(model, "model_neural_network")

                if "models" not in st.session_state:
                    st.session_state["models"] = {}
                model_name = f"neural_network_{activation}_{hidden_layer_sizes[0]}"
                count = 1
                base_model_name = model_name
                while model_name in st.session_state["models"]:
                    model_name = f"{base_model_name}_{count}"
                    count += 1
                st.session_state["models"][model_name] = model
                st.write(f"ğŸ”¹ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")
                st.write(f"Tá»•ng sá»‘ mÃ´ hÃ¬nh hiá»‡n táº¡i: {len(st.session_state['models'])}")
                st.session_state["last_trained_model"] = model_name
                st.write("ğŸ“‹ Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:")
                model_names = list(st.session_state["models"].keys())
                st.write(", ".join(model_names))

                status_text.text("âœ… HoÃ n táº¥t huáº¥n luyá»‡n!")
                progress_bar.progress(100)
                st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho **Train_{st.session_state['run_name']}**!")
                if "mlflow_url" in st.session_state:
                    st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")
                else:
                    st.warning("âš ï¸ URL MLflow chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p.")

            except Exception as e:
                st.error(f"âŒ Lá»—i khi huáº¥n luyá»‡n: {str(e)}")
                mlflow.end_run()
                progress_bar.progress(0)
                status_text.text("âŒ Huáº¥n luyá»‡n tháº¥t báº¡i!")

# HÃ m dá»± Ä‘oÃ¡n (giá»¯ nguyÃªn)
def du_doan():
    st.header("âœï¸ Váº½ sá»‘ Ä‘á»ƒ dá»± Ä‘oÃ¡n")
    model_names = list(st.session_state.get("models", {}).keys())
    if model_names:
        model_option = st.selectbox("ğŸ” Chá»n mÃ´ hÃ¬nh:", model_names)
        model = st.session_state["models"][model_option]
        st.success(f"âœ… ÄÃ£ chá»n mÃ´ hÃ¬nh tá»« session_state: {model_option}")
    else:
        st.warning("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c huáº¥n luyá»‡n.")
        return

    if "key_value" not in st.session_state:
        st.session_state.key_value = str(np.random.randint(0, 1000000))

    if st.button("ğŸ”„ Táº£i láº¡i náº¿u khÃ´ng tháº¥y canvas"):
        st.session_state.key_value = str(np.random.randint(0, 1000000))
        st.rerun()

    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key=st.session_state.key_value,
        update_streamlit=True
    )

    if st.button("Dá»± Ä‘oÃ¡n sá»‘"):
        img = preprocess_canvas_image(canvas_result)
        if img is not None:
            st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="áº¢nh sau xá»­ lÃ½", width=100)
            prediction = model.predict(img)
            st.subheader(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: {prediction[0]}")
        else:
            st.error("âš ï¸ HÃ£y váº½ má»™t sá»‘ trÆ°á»›c khi báº¥m Dá»± Ä‘oÃ¡n!")

# HÃ m hiá»ƒn thá»‹ experiment MLflow (giá»¯ nguyÃªn)
def show_experiment_selector():
    st.title("ğŸ“Š MLflow Experiments - DAGsHub")
    experiments = mlflow.search_experiments()
    experiment_names = [exp.name for exp in experiments]
    selected_experiment_name = st.selectbox("ğŸ” Chá»n má»™t Experiment:", experiment_names)
    if not selected_experiment_name:
        st.error(f"âŒ Experiment '{selected_experiment_name}' khÃ´ng tá»“n táº¡i!")
        return
    selected_experiment = next((exp for exp in experiments if exp.name == selected_experiment_name), None)
    if not selected_experiment:
        st.error("âŒ KhÃ´ng tÃ¬m tháº¥y experiment trong danh sÃ¡ch.")
        return
    st.subheader(f"ğŸ“Œ Experiment: {selected_experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tráº¡ng thÃ¡i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**Vá»‹ trÃ­ lÆ°u trá»¯:** {selected_experiment.artifact_location}")
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])
    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return
    st.write("### ğŸƒâ€â™‚ï¸ CÃ¡c Runs gáº§n Ä‘Ã¢y:")
    run_info = []
    for run_id in runs["run_id"]:
        run = mlflow.get_run(run_id)
        run_name = run.data.params.get("run_name", f"Run {run_id[:8]}")
        run_info.append((run_name, run_id))
    run_info.sort(key=lambda x: mlflow.get_run(x[1]).info.start_time, reverse=True)
    if run_info:
        latest_run_name, latest_run_id = run_info[0]
        selected_run_name = latest_run_name
        selected_run_id = latest_run_id
    else:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return
    selected_run = mlflow.get_run(selected_run_id)
    if selected_run:
        st.subheader(f"ğŸ“Œ ThÃ´ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
        start_time_ms = selected_run.info.start_time
        start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "KhÃ´ng cÃ³ thÃ´ng tin"
        st.write(f"**Thá»i gian cháº¡y:** {start_time}")
        params = selected_run.data.params
        metrics = selected_run.data.metrics
        if params:
            st.write("### âš™ï¸ Parameters:")
            st.json(params)
        if metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(metrics)

# HÃ m lÃ½ thuyáº¿t Neural Network (giá»¯ nguyÃªn)
def ly_thuyet_neural_network():
    st.markdown('<h1 style="color:#FF4500; text-align:center;">Neural Network (Máº¡ng NÆ¡-ron NhÃ¢n táº¡o)</h1>', unsafe_allow_html=True)
    st.markdown('<p style="font-size:24px; color:#4682B4;">ğŸ“ TÃ¬m hiá»ƒu vá» Máº¡ng NÆ¡-ron NhÃ¢n táº¡o (Neural Network) vÃ  cÃ¡ch nÃ³ hoáº¡t Ä‘á»™ng trong phÃ¢n loáº¡i dá»¯ liá»‡u.</p>', unsafe_allow_html=True)
    st.markdown('<h2 style="font-size:32px; color:#32CD32;">ğŸ“š 1. Neural Network lÃ  gÃ¬ vÃ  cÃ¡ch hoáº¡t Ä‘á»™ng?</h2>', unsafe_allow_html=True)
    st.markdown('<p style="font-size:22px;">â“ Máº¡ng NÆ¡-ron NhÃ¢n táº¡o (Artificial Neural Network - ANN) lÃ  mÃ´ hÃ¬nh há»c mÃ¡y láº¥y cáº£m há»©ng tá»« cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a nÃ£o bá»™ ngÆ°á»i. NÃ³ bao gá»“m nhiá»u nÆ¡-ron nhÃ¢n táº¡o Ä‘Æ°á»£c tá»• chá»©c thÃ nh cÃ¡c lá»›p Ä‘á»ƒ há»c vÃ  dá»± Ä‘oÃ¡n tá»« dá»¯ liá»‡u phá»©c táº¡p nhÆ° chá»¯ sá»‘ viáº¿t tay trong MNIST.<br>ğŸš€ <b>CÃ¡c khÃ¡i niá»‡m chÃ­nh:</b><br>- NÆ¡-ron (Neuron): ÄÆ¡n vá»‹ cÆ¡ báº£n nháº­n Ä‘áº§u vÃ o, Ã¡p dá»¥ng trá»ng sá»‘ vÃ  bias, sau Ä‘Ã³ chuyá»ƒn qua hÃ m kÃ­ch hoáº¡t.<br>- Lá»›p Ä‘áº§u vÃ o (Input Layer): Nháº­n dá»¯ liá»‡u thÃ´ (vÃ­ dá»¥: 784 pixel tá»« áº£nh 28x28).<br>- Lá»›p áº©n (Hidden Layer): Xá»­ lÃ½ cÃ¡c Ä‘áº·c trÆ°ng trung gian.<br>- Lá»›p Ä‘áº§u ra (Output Layer): ÄÆ°a ra káº¿t quáº£ dá»± Ä‘oÃ¡n (vÃ­ dá»¥: 10 lá»›p tá»« 0-9).<br>ğŸ“ <b>QuÃ¡ trÃ¬nh há»c:</b><br></p>', unsafe_allow_html=True)
    st.markdown('<p style="font-size:22px;">- Forward Propagation: TÃ­nh toÃ¡n Ä‘áº§u ra tá»« Ä‘áº§u vÃ o qua cÃ¡c lá»›p.<br>- Backpropagation: Lan truyá»n ngÆ°á»£c lá»—i Ä‘á»ƒ cáº­p nháº­t trá»ng sá»‘.<br></p>', unsafe_allow_html=True)
    st.latex(r'z = w^T x + b')
    st.markdown("Trong Ä‘Ã³: - \( z \): Tá»•ng cÃ³ trá»ng sá»‘ trÆ°á»›c hÃ m kÃ­ch hoáº¡t. - \( w \): Trá»ng sá»‘. - \( x \): Äáº§u vÃ o. - \( b \): Bias.")
    st.latex(r'a = f(z)')
    st.markdown("Trong Ä‘Ã³: - \( a \): Äáº§u ra sau hÃ m kÃ­ch hoáº¡t \( f \).")
    st.markdown('<h2 style="font-size:32px; color:#FFD700;">ğŸ“ 2. HÃ m kÃ­ch hoáº¡t (Activation Functions)</h2>', unsafe_allow_html=True)
    st.markdown('<p style="font-size:22px;">- HÃ m kÃ­ch hoáº¡t giÃºp giá»›i thiá»‡u tÃ­nh phi tuyáº¿n, quan trá»ng Ä‘á»ƒ mÃ´ hÃ¬nh há»c cÃ¡c máº«u phá»©c táº¡p.<br></p>', unsafe_allow_html=True)
    st.latex(r'f(z) = \frac{1}{1 + e^{-z}}')
    st.markdown("Trong Ä‘Ã³: - \( f(z) \): Äáº§u ra trong khoáº£ng (0, 1), phÃ¹ há»£p cho phÃ¢n loáº¡i nhá»‹ phÃ¢n.")
    st.latex(r'f(z) = \max(0, z)')
    st.markdown("Trong Ä‘Ã³: - \( f(z) \): Äáº§u ra lÃ  \( z \) náº¿u \( z > 0 \), báº±ng 0 náº¿u \( z \leq 0 \), giáº£m váº¥n Ä‘á» gradient vanishing.")
    st.latex(r'f(z) = \tanh(z)')
    st.markdown("Trong Ä‘Ã³: - \( f(z) \): Äáº§u ra trong khoáº£ng (-1, 1), cÃ¢n báº±ng dá»¯ liá»‡u tá»‘t hÆ¡n sigmoid.")
    st.markdown('<h2 style="font-size:32px; color:#00CED1;">ğŸ“ˆ 3. QuÃ¡ trÃ¬nh há»c vÃ  Backpropagation</h2>', unsafe_allow_html=True)
    st.markdown('<p style="font-size:22px;">- **HÃ m máº¥t mÃ¡t (Loss Function)**: Äo sai lá»‡ch giá»¯a dá»± Ä‘oÃ¡n vÃ  giÃ¡ trá»‹ thá»±c táº¿.<br></p>', unsafe_allow_html=True)
    st.latex(r'L = \frac{1}{2} \sum (y - \hat{y})^2')
    st.markdown("Trong Ä‘Ã³: - \( L \): GiÃ¡ trá»‹ máº¥t mÃ¡t. - \( y \): GiÃ¡ trá»‹ thá»±c táº¿. - \( \hat{y} \): GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n.")
    st.latex(r'w_{new} = w_{old} - \eta \frac{\partial L}{\partial w}')
    st.markdown("Trong Ä‘Ã³: - \( \eta \): Tá»‘c Ä‘á»™ há»c (learning rate). - \( \frac{\partial L}{\partial w} \): Gradient cá»§a hÃ m máº¥t mÃ¡t theo trá»ng sá»‘.")
    st.markdown('<h2 style="font-size:32px; color:#FF69B4;">ğŸ“Š 4. VÃ­ dá»¥ minh há»a trÃªn MNIST</h2>', unsafe_allow_html=True)
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.bar(range(10), np.bincount([int(i) for i in y[:100]]))
    ax.set_title("PhÃ¢n bá»‘ lá»›p trong 100 máº«u MNIST")
    ax.set_xlabel("Sá»‘")
    ax.set_ylabel("Sá»‘ lÆ°á»£ng")
    st.pyplot(fig)
    st.markdown('<p style="font-size:18px;">ğŸ“Š Biá»ƒu Ä‘á»“ trÃªn thá»ƒ hiá»‡n phÃ¢n bá»‘ cÃ¡c chá»¯ sá»‘ trong 100 máº«u Ä‘áº§u tiÃªn cá»§a MNIST.</p>', unsafe_allow_html=True)
    st.markdown('<h2 style="font-size:32px; color:#FFA500;">âš ï¸ 5. Æ¯u Ä‘iá»ƒm, háº¡n cháº¿ vÃ  á»©ng dá»¥ng</h2>', unsafe_allow_html=True)
    st.markdown('<p style="font-size:22px;">ğŸ‘ **Æ¯u Ä‘iá»ƒm**: - Linh hoáº¡t vá»›i dá»¯ liá»‡u phá»©c táº¡p nhÆ° hÃ¬nh áº£nh, Ã¢m thanh.<br>- CÃ³ kháº£ nÄƒng há»c cÃ¡c Ä‘áº·c trÆ°ng khÃ´ng tuyáº¿n tÃ­nh.<br>ğŸ‘ **Háº¡n cháº¿**: - Tá»‘n tÃ i nguyÃªn tÃ­nh toÃ¡n lá»›n.<br>- Dá»… bá»‹ overfitting náº¿u khÃ´ng Ä‘iá»u chá»‰nh ká»¹.<br>ğŸŒ **á»¨ng dá»¥ng**: Nháº­n diá»‡n chá»¯ sá»‘ (MNIST), xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, xe tá»± hÃ nh.<br></p>', unsafe_allow_html=True)
    st.markdown('<h2 style="font-size:32px; color:#1E90FF;">ğŸ”— 6. TÃ i liá»‡u tham kháº£o</h2>', unsafe_allow_html=True)
    st.markdown('<p style="font-size:22px;">ğŸ“– Xem chi tiáº¿t táº¡i <a href="https://kdientu.duytan.edu.vn/media/50176/ly-thuyet-mang-neural.pdf?form=MG0AV3">TÃ i liá»‡u Neural Network - Äáº¡i há»c Duy TÃ¢n</a>.</p>', unsafe_allow_html=True)
    st.markdown('<p style="font-size:20px; color:#6A5ACD;">ğŸ™ Cáº£m Æ¡n báº¡n Ä‘Ã£ khÃ¡m phÃ¡ Neural Network!</p>', unsafe_allow_html=True)

# HÃ m xá»­ lÃ½ áº£nh tá»« canvas (giá»¯ nguyÃªn)
def preprocess_canvas_image(canvas_result):
    if canvas_result.image_data is not None:
        img = Image.fromarray(canvas_result.image_data[:, :, 0].astype(np.uint8))
        img = img.resize((28, 28)).convert("L")
        img = np.array(img, dtype=np.float32) / 255.0
        return img.reshape(1, -1)
    return None

# HÃ m Pseudo Labeling (Ä‘Ã£ sá»­a vá»›i key duy nháº¥t)
def pseudo_labeling():
    st.header("ğŸ¯ Pseudo Labeling vá»›i Neural Network trÃªn MNIST")

    if "data_split_done" not in st.session_state or "X_train" not in st.session_state:
        st.error("âš ï¸ Vui lÃ²ng chia dá»¯ liá»‡u trÆ°á»›c á»Ÿ tab 'Chia dá»¯ liá»‡u Train/Test'!")
        st.button("ğŸ”™ Quay láº¡i bÆ°á»›c chia dá»¯ liá»‡u", on_click=lambda: st.session_state.update({"page": "data_split"}))
        return

    X_train_full = st.session_state.X_train
    y_train_full = st.session_state.y_train
    X_test = st.session_state.X_test
    y_test = st.session_state.y_test

    st.markdown("""
    <p style="font-size:20px;">
    ğŸ“‹ **Quy trÃ¬nh Pseudo Labeling**:<br>
    (0) Chia táº­p train/test ban Ä‘áº§u.<br>
    (1) Láº¥y 1% sá»‘ lÆ°á»£ng áº£nh cho má»—i class (0-9) lÃ m táº­p train ban Ä‘áº§u.<br>
    (2) Huáº¥n luyá»‡n mÃ´ hÃ¬nh NN trÃªn táº­p 1% nÃ y.<br>
    (3) Dá»± Ä‘oÃ¡n nhÃ£n cho 99% dá»¯ liá»‡u cÃ²n láº¡i.<br>
    (4) GÃ¡n Pseudo Label vá»›i ngÆ°á»¡ng (threshold) cho cÃ¡c máº«u cÃ³ Ä‘á»™ tin cáº­y cao.<br>
    (5) Láº·p láº¡i tá»« bÆ°á»›c (2) vá»›i táº­p dá»¯ liá»‡u má»›i cho Ä‘áº¿n khi gÃ¡n háº¿t nhÃ£n hoáº·c Ä‘áº¡t sá»‘ bÆ°á»›c láº·p tá»‘i Ä‘a.<br>
    </p>
    """, unsafe_allow_html=True)

    # Chá»n tham sá»‘ vá»›i key duy nháº¥t
    threshold = st.slider("ğŸ“Œ NgÆ°á»¡ng quyáº¿t Ä‘á»‹nh (Threshold) cho Pseudo Label", 0.5, 1.0, 0.95, step=0.05, key="pseudo_threshold")
    max_iterations = st.slider("ğŸ“Œ Sá»‘ bÆ°á»›c láº·p tá»‘i Ä‘a", 1, 10, 5, key="pseudo_max_iterations")
    hidden_layer_sizes = st.slider("Hidden Layer Sizes", 10, 200, (100,), step=10, key="pseudo_hidden_layer_sizes")
    activation = st.selectbox("Activation Function", ["relu", "tanh"], key="pseudo_activation")
    learning_rate_init = st.slider("Learning Rate", 0.001, 0.1, 0.01, step=0.001, key="pseudo_learning_rate")
    max_iter = st.slider("Max Iterations", 100, 1000, 500, step=100, key="pseudo_max_iter")

    if st.button("ğŸ¬ Báº¯t Ä‘áº§u Pseudo Labeling"):
        progress_bar = st.progress(0)
        status_text = st.empty()

        # BÆ°á»›c (1): Láº¥y 1% dá»¯ liá»‡u cho má»—i class
        status_text.text("ğŸ”„ Äang láº¥y 1% dá»¯ liá»‡u ban Ä‘áº§u cho má»—i class...")
        progress_bar.progress(10)
        num_classes = 10
        samples_per_class = int(len(X_train_full) * 0.01 / num_classes)
        X_labeled = np.array([])
        y_labeled = np.array([])
        for cls in range(num_classes):
            indices = np.where(y_train_full == str(cls))[0]
            if len(indices) > samples_per_class:
                selected_indices = np.random.choice(indices, samples_per_class, replace=False)
            else:
                selected_indices = indices
            X_labeled = np.concatenate((X_labeled, X_train_full[selected_indices])) if X_labeled.size else X_train_full[selected_indices]
            y_labeled = np.concatenate((y_labeled, y_train_full[selected_indices].astype(float))) if y_labeled.size else y_train_full[selected_indices].astype(float)
        X_unlabeled = np.delete(X_train_full, np.unique(np.concatenate([np.where(y_train_full == str(cls))[0] for cls in range(num_classes)])), axis=0)
        y_unlabeled = np.array(["unlabeled"] * len(X_unlabeled))

        # Biáº¿n Ä‘á»ƒ theo dÃµi sá»‘ máº«u Ä‘Ã£ gÃ¡n nhÃ£n
        labeled_count = len(y_labeled)
        total_samples = len(X_train_full)
        iteration = 0

        while iteration < max_iterations and labeled_count < total_samples:
            status_text.text(f"â³ Äang thá»±c hiá»‡n bÆ°á»›c láº·p {iteration + 1}/{max_iterations}...")
            progress_bar.progress(int((iteration + 1) * 100 / max_iterations))

            # BÆ°á»›c (2): Huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u Ä‘Ã£ gÃ¡n nhÃ£n
            model = MLPClassifier(
                hidden_layer_sizes=hidden_layer_sizes,
                activation=activation,
                learning_rate_init=learning_rate_init,
                max_iter=max_iter,
                random_state=42
            )
            model.fit(X_labeled, y_labeled)
            mlflow.start_run(run_name=f"Pseudo_Labeling_Iter_{iteration}")
            mlflow.log_param("threshold", threshold)
            mlflow.log_param("iteration", iteration)
            mlflow.log_param("labeled_samples", len(y_labeled))
            mlflow.log_metric("accuracy_on_test", accuracy_score(y_test, model.predict(X_test)))
            mlflow.sklearn.log_model(model, f"model_iter_{iteration}")
            mlflow.end_run()

            # BÆ°á»›c (3): Dá»± Ä‘oÃ¡n nhÃ£n cho dá»¯ liá»‡u chÆ°a gÃ¡n nhÃ£n
            probabilities = model.predict_proba(X_unlabeled)
            y_pred_unlabeled = model.predict(X_unlabeled)
            confidence = np.max(probabilities, axis=1)

            # BÆ°á»›c (4): GÃ¡n Pseudo Label vá»›i ngÆ°á»¡ng
            mask = confidence >= threshold
            new_labeled_indices = np.where(mask)[0]
            if len(new_labeled_indices) == 0:
                st.warning(f"âš ï¸ KhÃ´ng cÃ³ máº«u nÃ o Ä‘áº¡t ngÆ°á»¡ng {threshold} á»Ÿ bÆ°á»›c láº·p {iteration + 1}. Káº¿t thÃºc!")
                break

            X_new_labeled = X_unlabeled[new_labeled_indices]
            y_new_labeled = y_pred_unlabeled[new_labeled_indices]
            X_labeled = np.concatenate((X_labeled, X_new_labeled))
            y_labeled = np.concatenate((y_labeled, y_new_labeled))
            X_unlabeled = np.delete(X_unlabeled, new_labeled_indices, axis=0)
            y_unlabeled = np.delete(y_unlabeled, new_labeled_indices)

            labeled_count = len(y_labeled)
            st.success(f"âœ… BÆ°á»›c {iteration + 1}: ÄÃ£ gÃ¡n nhÃ£n cho {len(new_labeled_indices)} máº«u. Tá»•ng sá»‘ máº«u Ä‘Ã£ gÃ¡n: {labeled_count}/{total_samples}")

            iteration += 1

        # Káº¿t thÃºc
        status_text.text("âœ… HoÃ n táº¥t Pseudo Labeling!")
        progress_bar.progress(100)
        st.write(f"ğŸ“Š Tá»•ng sá»‘ máº«u Ä‘Ã£ gÃ¡n nhÃ£n: {labeled_count}/{total_samples}")
        if labeled_count == total_samples:
            st.success("ğŸ‰ ÄÃ£ gÃ¡n nhÃ£n cho toÃ n bá»™ táº­p train ban Ä‘áº§u!")
        else:
            st.warning(f"âš ï¸ Chá»‰ gÃ¡n nhÃ£n Ä‘Æ°á»£c {labeled_count} máº«u sau {iteration} bÆ°á»›c láº·p.")

        # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh cuá»‘i cÃ¹ng
        final_model = MLPClassifier(
            hidden_layer_sizes=hidden_layer_sizes,
            activation=activation,
            learning_rate_init=learning_rate_init,
            max_iter=max_iter,
            random_state=42
        )
        final_model.fit(X_labeled, y_labeled)
        final_accuracy = accuracy_score(y_test, final_model.predict(X_test))
        st.success(f"âœ… Äá»™ chÃ­nh xÃ¡c trÃªn test set vá»›i mÃ´ hÃ¬nh cuá»‘i cÃ¹ng: {final_accuracy:.4f}")

def data():
    st.markdown("""
        <h1 style="text-align: center; color: #1E90FF; font-size: 48px; text-shadow: 2px 2px 4px #000000;">
             KhÃ¡m PhÃ¡ Bá»™ Dá»¯ Liá»‡u MNIST
        </h1>
        <style>
        @keyframes fadeIn { from {opacity: 0;} to {opacity: 1;} }
        </style>
    """, unsafe_allow_html=True)

    st.markdown("""
        <div style="background-color: #F0F8FF; padding: 20px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            <h2 style="color: #32CD32; font-size: 32px;">ğŸ“Š Tá»•ng Quan Vá» MNIST</h2>
            <p style="font-size: 20px; color: #333; text-align: justify;">
                MNIST (Modified National Institute of Standards and Technology) lÃ  bá»™ dá»¯ liá»‡u <b>huyá»n thoáº¡i</b> 
                trong nháº­n diá»‡n chá»¯ sá»‘ viáº¿t tay, vá»›i <b>70.000 áº£nh</b> (60.000 train, 10.000 test), má»—i áº£nh 
                cÃ³ kÃ­ch thÆ°á»›c <b>28x28 pixel</b> grayscale.
            </p>
        </div>
    """, unsafe_allow_html=True)

    X, y = load_mnist_data()
    fig, ax = plt.subplots(1, 5, figsize=(15, 3))
    for i in range(5):
        ax[i].imshow(X[i].reshape(28, 28), cmap='gray')
        ax[i].axis('off')
        ax[i].set_title(f"NhÃ£n: {int(y[i])}")
    # Sá»­ dá»¥ng st.pyplot() thay vÃ¬ st.image()
    st.pyplot(fig)

    st.markdown("""
        <h2 style="color: #FF4500; font-size: 32px;">ğŸŒ á»¨ng Dá»¥ng Thá»±c Táº¿</h2>
        <div style="display: flex; gap: 20px;">
            <div style="background-color: #ECF0F1; padding: 15px; border-radius: 10px; flex: 1;">
                <p style="font-size: 20px; color: #2E86C1;">Nháº­n diá»‡n sá»‘ trÃªn hÃ³a Ä‘Æ¡n.</p>
            </div>
            <div style="background-color: #ECF0F1; padding: 15px; border-radius: 10px; flex: 1;">
                <p style="font-size: 20px; color: #2E86C1;">Xá»­ lÃ½ mÃ£ bÆ°u kiá»‡n.</p>
            </div>
        </div>
    """, unsafe_allow_html=True)

    st.markdown("<h2 style='color: #8A2BE2; font-size: 32px;'>ğŸ† Hiá»‡u Suáº¥t MÃ´ HÃ¬nh</h2>", unsafe_allow_html=True)
    data = {"MÃ´ hÃ¬nh": ["Neural Network", "SVM", "CNN"], "Äá»™ chÃ­nh xÃ¡c": ["0.98", "0.97", "0.99"]}
    df = pd.DataFrame(data)
    st.table(df.style.set_properties(**{'background-color': '#F5F5F5', 'border': '1px solid #DDD', 'text-align': 'center', 'font-size': '18px'}).set_table_styles([{'selector': 'th', 'props': [('background-color', '#3498DB'), ('color', 'white')]}]))

# HÃ m chÃ­nh Ä‘á»ƒ tÃ­ch há»£p táº¥t cáº£ cÃ¡c tab
def Classification():
    if "mlflow_initialized" not in st.session_state:
        DAGSHUB_MLFLOW_URI = "https://dagshub.com/PTToan250303/Linear_replication.mlflow"
        mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
        st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
        os.environ["MLFLOW_TRACKING_USERNAME"] = "PTToan250303"
        os.environ["MLFLOW_TRACKING_PASSWORD"] = "5ca8caf353d564c358852da97c7487e64fc30a73"
        mlflow.set_experiment("Neural_Network_Classification")

    st.markdown("""
        <style>
        .title { font-size: 48px; font-weight: bold; text-align: center; color: #4682B4; margin-top: 50px; }
        .subtitle { font-size: 24px; text-align: center; color: #4A4A4A; }
        hr { border: 1px solid #ddd; }
        </style>
        <div class="title">MNIST Neural Network App</div>
        <hr>
    """, unsafe_allow_html=True)

    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ“˜ LÃ½ thuyáº¿t Neural Network", "ğŸ“˜ Data", "âš™ï¸ Huáº¥n luyá»‡n", "ğŸ”¢ Dá»± Ä‘oÃ¡n", "ğŸ”¥ Mlflow", "ğŸ¯ Pseudo Labeling"])

    with tab1:
        ly_thuyet_neural_network()
    with tab2:
        data()
    with tab3:
        split_data()
        train()
    with tab4:
        du_doan()
    with tab5:
        show_experiment_selector()
    with tab6:
        pseudo_labeling()

if __name__ == "__main__":
    Classification()